{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceType": "datasetVersion",
     "sourceId": 10270002,
     "datasetId": 6354126,
     "databundleVersionId": 10569562
    },
    {
     "sourceType": "datasetVersion",
     "sourceId": 10271842,
     "datasetId": 6355470,
     "databundleVersionId": 10571629
    },
    {
     "sourceType": "datasetVersion",
     "sourceId": 10264339,
     "datasetId": 6349994,
     "databundleVersionId": 10563001
    },
    {
     "sourceType": "datasetVersion",
     "sourceId": 10271953,
     "datasetId": 6355558,
     "databundleVersionId": 10571758
    },
    {
     "sourceType": "datasetVersion",
     "sourceId": 10277931,
     "datasetId": 6359747,
     "databundleVersionId": 10578429
    },
    {
     "sourceType": "datasetVersion",
     "sourceId": 109264,
     "datasetId": 56828,
     "databundleVersionId": 119232
    },
    {
     "sourceType": "modelInstanceVersion",
     "sourceId": 205778,
     "databundleVersionId": 10562225,
     "modelInstanceId": 175504
    }
   ],
   "dockerImageVersionId": 30823,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Download Datasets",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Download Cityscapes",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# The following code will only execute\n# successfully when compression is complete\n\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"alessiogio/cityscapes-correctlabels\")\n\nprint(\"Path to dataset files:\", path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-22T13:30:59.505814Z",
     "iopub.execute_input": "2024-12-22T13:30:59.506173Z",
     "iopub.status.idle": "2024-12-22T13:35:22.948900Z",
     "shell.execute_reply.started": "2024-12-22T13:30:59.506144Z",
     "shell.execute_reply": "2024-12-22T13:35:22.947832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Mounting files to /kaggle/input/cityscapes-correctlabels...\nPath to dataset files: /kaggle/input/cityscapes-correctlabels\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "### Download Tiny Imagenet",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n\nprint(\"Path to dataset files:\", path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-21T10:59:57.207506Z",
     "iopub.execute_input": "2024-12-21T10:59:57.207808Z",
     "iopub.status.idle": "2024-12-21T10:59:57.707500Z",
     "shell.execute_reply.started": "2024-12-21T10:59:57.207785Z",
     "shell.execute_reply": "2024-12-21T10:59:57.706618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Path to dataset files: /kaggle/input/tiny-imagenet\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "### Download fishyscapes- lost and found",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"alessiogio/fs-l-and-f\")\n\nprint(\"Path to dataset files:\", path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-22T17:22:51.289979Z",
     "iopub.execute_input": "2024-12-22T17:22:51.290415Z",
     "iopub.status.idle": "2024-12-22T17:22:57.594258Z",
     "shell.execute_reply.started": "2024-12-22T17:22:51.290383Z",
     "shell.execute_reply": "2024-12-22T17:22:57.592948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Path to dataset files: /kaggle/input/fs-l-and-f\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "### Download SMIYC Road Anomaly 21",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# The following code will only execute\n# successfully when compression is complete\n\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"alessiogio/smiyc-road-anomaly-21\")\n\nprint(\"Path to dataset files:\", path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-22T17:46:37.847998Z",
     "iopub.execute_input": "2024-12-22T17:46:37.848301Z",
     "iopub.status.idle": "2024-12-22T17:46:44.830142Z",
     "shell.execute_reply.started": "2024-12-22T17:46:37.848280Z",
     "shell.execute_reply": "2024-12-22T17:46:44.829372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Path to dataset files: /kaggle/input/smiyc-road-anomaly-21\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "### Download SMIYC Road Obstacles 21",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# The following code will only execute\n# successfully when compression is complete\n\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"alessiogio/smiyc-road-obstacles-21\")\n\nprint(\"Path to dataset files:\", path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-23T10:45:33.506556Z",
     "iopub.execute_input": "2024-12-23T10:45:33.506773Z",
     "iopub.status.idle": "2024-12-23T10:45:45.334759Z",
     "shell.execute_reply.started": "2024-12-23T10:45:33.506744Z",
     "shell.execute_reply": "2024-12-23T10:45:45.333829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Path to dataset files: /kaggle/input/smiyc-road-obstacles-21\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "## Git Clone",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!git clone -b prova-2 https://github.com/Nome-Provvisorio/AnomalySegmentation.git",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-23T10:55:38.578817Z",
     "iopub.execute_input": "2024-12-23T10:55:38.579198Z",
     "iopub.status.idle": "2024-12-23T10:55:42.354824Z",
     "shell.execute_reply.started": "2024-12-23T10:55:38.579166Z",
     "shell.execute_reply": "2024-12-23T10:55:42.353989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Cloning into 'AnomalySegmentation'...\nremote: Enumerating objects: 245, done.\u001B[K\nremote: Counting objects: 100% (56/56), done.\u001B[K\nremote: Compressing objects: 100% (56/56), done.\u001B[K\nremote: Total 245 (delta 38), reused 0 (delta 0), pack-reused 189 (from 1)\u001B[K\nReceiving objects: 100% (245/245), 79.75 MiB | 40.95 MiB/s, done.\nResolving deltas: 100% (148/148), done.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "!git pull origin main",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-22T10:14:39.138456Z",
     "iopub.execute_input": "2024-12-22T10:14:39.138791Z",
     "iopub.status.idle": "2024-12-22T10:14:39.256935Z",
     "shell.execute_reply.started": "2024-12-22T10:14:39.138764Z",
     "shell.execute_reply": "2024-12-22T10:14:39.255910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "fatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install visdom\n",
    "!pip install cv2\n",
    "#!pip install torch_xla\n",
    "\n",
    "#!pip install cityscapesscripts\n",
    "!pip install ood_metrics"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-23T10:55:51.043887Z",
     "iopub.execute_input": "2024-12-23T10:55:51.044172Z",
     "iopub.status.idle": "2024-12-23T10:56:07.069438Z",
     "shell.execute_reply.started": "2024-12-23T10:55:51.044151Z",
     "shell.execute_reply": "2024-12-23T10:56:07.068632Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-23T11:15:37.943868Z",
     "start_time": "2024-12-23T11:15:32.910220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: visdom in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: numpy>=1.8 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (1.26.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (1.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (2.32.3)\n",
      "Requirement already satisfied: tornado in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (6.4.2)\n",
      "Requirement already satisfied: six in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (1.16.0)\n",
      "Requirement already satisfied: jsonpatch in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (1.33)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (1.8.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (3.2.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visdom) (10.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch->visdom) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->visdom) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->visdom) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->visdom) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->visdom) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ood_metrics in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: matplotlib<4.0,>=3.0 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ood_metrics) (3.9.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.22 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ood_metrics) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.0 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ood_metrics) (1.5.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn<2.0,>=1.0->ood_metrics) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn<2.0,>=1.0->ood_metrics) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn<2.0,>=1.0->ood_metrics) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vcata\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0,>=3.0->ood_metrics) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": "## Run Pretraining",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%cd \"/kaggle/working\"\n!python3 \"AnomalySegmentation/imagenet/main.py\" \"/kaggle/input/tiny-imagenet/tiny-imagenet-200\"",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-21T15:22:06.841245Z",
     "iopub.execute_input": "2024-12-21T15:22:06.841524Z",
     "iopub.status.idle": "2024-12-21T15:22:07.051585Z",
     "shell.execute_reply.started": "2024-12-21T15:22:06.841501Z",
     "shell.execute_reply": "2024-12-21T15:22:07.050428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/working\npython3: can't open file '/kaggle/working/AnomalySegmentation/imagenet/main.py': [Errno 2] No such file or directory\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "## Run training",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%cd \"/kaggle/working/AnomalySegmentation/train\"\n!python3 \"main.py\" --savedir erfnet_training1 --datadir \"/kaggle/input/cityscapes-correctlabels/Cityscape\" --num-epochs 10 --batch-size 1 --decoder --pretrainedEncoder \"/kaggle/working/AnomalySegmentation/train/model_best.pth.tar\"",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-22T14:59:06.319164Z",
     "iopub.execute_input": "2024-12-22T14:59:06.319561Z",
     "iopub.status.idle": "2024-12-22T15:46:03.443058Z",
     "shell.execute_reply.started": "2024-12-22T14:59:06.319520Z",
     "shell.execute_reply": "2024-12-22T15:46:03.442174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/working/AnomalySegmentation/train\nmodel path is:  erfnet\nCurrent working directory: /kaggle/working/AnomalySegmentation/train\n========== DECODER TRAINING ===========\nLoading encoder pretrained in imagenet\n/kaggle/working/AnomalySegmentation/train/main.py:492: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pretrainedEnc.load_state_dict(torch.load(args.pretrainedEncoder)['state_dict'])\nTraining dataset path: /kaggle/input/cityscapes-correctlabels/Cityscape\nImages path: /kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/train\nLabels path: /kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/train\nNumber of image files: 2975\nNumber of label files: 2975\nSample image filenames:\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/train/aachen/aachen_000000_000019_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/train/aachen/aachen_000001_000019_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/train/aachen/aachen_000002_000019_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/train/aachen/aachen_000003_000019_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/train/aachen/aachen_000004_000019_leftImg8bit.png\nSample label filenames:\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/train/aachen/aachen_000000_000019_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/train/aachen/aachen_000001_000019_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/train/aachen/aachen_000002_000019_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/train/aachen/aachen_000003_000019_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/train/aachen/aachen_000004_000019_gtFine_labelTrainIds.png\nNumber of valid image-label pairs: 2975\nImages path: /kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/val\nLabels path: /kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/val\nNumber of image files: 500\nNumber of label files: 500\nSample image filenames:\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/val/frankfurt/frankfurt_000000_000576_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/val/frankfurt/frankfurt_000000_001016_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/val/frankfurt/frankfurt_000000_001236_leftImg8bit.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/leftImg8bit/val/frankfurt/frankfurt_000000_001751_leftImg8bit.png\nSample label filenames:\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/val/frankfurt/frankfurt_000000_000576_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/val/frankfurt/frankfurt_000000_001016_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/val/frankfurt/frankfurt_000000_001236_gtFine_labelTrainIds.png\n/kaggle/input/cityscapes-correctlabels/Cityscape/gtFine/val/frankfurt/frankfurt_000000_001751_gtFine_labelTrainIds.png\nNumber of valid image-label pairs: 500\n<class '__main__.CrossEntropyLoss2d'>\n----- TRAINING - EPOCH 1 -----\n/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\nLEARNING RATE:  0.0005\nloss: 3.102 (epoch: 1, step: 0) // Avg time/img: 1.0165 s\nloss: 2.763 (epoch: 1, step: 50) // Avg time/img: 0.0902 s\nloss: 2.528 (epoch: 1, step: 100) // Avg time/img: 0.0809 s\nloss: 2.316 (epoch: 1, step: 150) // Avg time/img: 0.0778 s\nloss: 2.152 (epoch: 1, step: 200) // Avg time/img: 0.0771 s\nloss: 2.007 (epoch: 1, step: 250) // Avg time/img: 0.0759 s\nloss: 1.882 (epoch: 1, step: 300) // Avg time/img: 0.0752 s\nloss: 1.801 (epoch: 1, step: 350) // Avg time/img: 0.0746 s\nloss: 1.712 (epoch: 1, step: 400) // Avg time/img: 0.0741 s\nloss: 1.639 (epoch: 1, step: 450) // Avg time/img: 0.0738 s\nloss: 1.586 (epoch: 1, step: 500) // Avg time/img: 0.0736 s\nloss: 1.547 (epoch: 1, step: 550) // Avg time/img: 0.0734 s\nloss: 1.509 (epoch: 1, step: 600) // Avg time/img: 0.0734 s\nloss: 1.479 (epoch: 1, step: 650) // Avg time/img: 0.0732 s\nloss: 1.447 (epoch: 1, step: 700) // Avg time/img: 0.0730 s\nloss: 1.423 (epoch: 1, step: 750) // Avg time/img: 0.0729 s\nloss: 1.399 (epoch: 1, step: 800) // Avg time/img: 0.0728 s\nloss: 1.377 (epoch: 1, step: 850) // Avg time/img: 0.0727 s\nloss: 1.353 (epoch: 1, step: 900) // Avg time/img: 0.0725 s\nloss: 1.328 (epoch: 1, step: 950) // Avg time/img: 0.0725 s\nloss: 1.311 (epoch: 1, step: 1000) // Avg time/img: 0.0724 s\nloss: 1.293 (epoch: 1, step: 1050) // Avg time/img: 0.0725 s\nloss: 1.276 (epoch: 1, step: 1100) // Avg time/img: 0.0725 s\nloss: 1.259 (epoch: 1, step: 1150) // Avg time/img: 0.0724 s\nloss: 1.243 (epoch: 1, step: 1200) // Avg time/img: 0.0723 s\nloss: 1.229 (epoch: 1, step: 1250) // Avg time/img: 0.0723 s\nloss: 1.215 (epoch: 1, step: 1300) // Avg time/img: 0.0723 s\nloss: 1.203 (epoch: 1, step: 1350) // Avg time/img: 0.0722 s\nloss: 1.188 (epoch: 1, step: 1400) // Avg time/img: 0.0722 s\nloss: 1.179 (epoch: 1, step: 1450) // Avg time/img: 0.0722 s\nloss: 1.171 (epoch: 1, step: 1500) // Avg time/img: 0.0722 s\nloss: 1.155 (epoch: 1, step: 1550) // Avg time/img: 0.0722 s\nloss: 1.147 (epoch: 1, step: 1600) // Avg time/img: 0.0721 s\nloss: 1.138 (epoch: 1, step: 1650) // Avg time/img: 0.0721 s\nloss: 1.126 (epoch: 1, step: 1700) // Avg time/img: 0.0721 s\nloss: 1.118 (epoch: 1, step: 1750) // Avg time/img: 0.0720 s\nloss: 1.107 (epoch: 1, step: 1800) // Avg time/img: 0.0720 s\nloss: 1.1 (epoch: 1, step: 1850) // Avg time/img: 0.0720 s\nloss: 1.09 (epoch: 1, step: 1900) // Avg time/img: 0.0720 s\nloss: 1.083 (epoch: 1, step: 1950) // Avg time/img: 0.0720 s\nloss: 1.075 (epoch: 1, step: 2000) // Avg time/img: 0.0720 s\nloss: 1.067 (epoch: 1, step: 2050) // Avg time/img: 0.0719 s\nloss: 1.059 (epoch: 1, step: 2100) // Avg time/img: 0.0719 s\nloss: 1.055 (epoch: 1, step: 2150) // Avg time/img: 0.0719 s\nloss: 1.046 (epoch: 1, step: 2200) // Avg time/img: 0.0719 s\nloss: 1.041 (epoch: 1, step: 2250) // Avg time/img: 0.0719 s\nloss: 1.034 (epoch: 1, step: 2300) // Avg time/img: 0.0719 s\nloss: 1.027 (epoch: 1, step: 2350) // Avg time/img: 0.0719 s\nloss: 1.023 (epoch: 1, step: 2400) // Avg time/img: 0.0719 s\nloss: 1.017 (epoch: 1, step: 2450) // Avg time/img: 0.0718 s\nloss: 1.011 (epoch: 1, step: 2500) // Avg time/img: 0.0718 s\nloss: 1.005 (epoch: 1, step: 2550) // Avg time/img: 0.0718 s\nloss: 0.9983 (epoch: 1, step: 2600) // Avg time/img: 0.0718 s\nloss: 0.9935 (epoch: 1, step: 2650) // Avg time/img: 0.0718 s\nloss: 0.9892 (epoch: 1, step: 2700) // Avg time/img: 0.0718 s\nloss: 0.9833 (epoch: 1, step: 2750) // Avg time/img: 0.0718 s\nloss: 0.9787 (epoch: 1, step: 2800) // Avg time/img: 0.0718 s\nloss: 0.9744 (epoch: 1, step: 2850) // Avg time/img: 0.0718 s\nloss: 0.9702 (epoch: 1, step: 2900) // Avg time/img: 0.0718 s\nloss: 0.9655 (epoch: 1, step: 2950) // Avg time/img: 0.0718 s\n----- VALIDATING - EPOCH 1 -----\nVAL loss: 0.6553 (epoch: 1, step: 0) // Avg time/img: 0.0357 s\nVAL loss: 0.9121 (epoch: 1, step: 50) // Avg time/img: 0.0256 s\nVAL loss: 1.004 (epoch: 1, step: 100) // Avg time/img: 0.0256 s\nVAL loss: 1.003 (epoch: 1, step: 150) // Avg time/img: 0.0255 s\nVAL loss: 0.9567 (epoch: 1, step: 200) // Avg time/img: 0.0255 s\nVAL loss: 0.9225 (epoch: 1, step: 250) // Avg time/img: 0.0256 s\nVAL loss: 0.9559 (epoch: 1, step: 300) // Avg time/img: 0.0256 s\nVAL loss: 0.9591 (epoch: 1, step: 350) // Avg time/img: 0.0256 s\nVAL loss: 0.9255 (epoch: 1, step: 400) // Avg time/img: 0.0256 s\nVAL loss: 0.8817 (epoch: 1, step: 450) // Avg time/img: 0.0256 s\nEPOCH IoU on VAL set:  \u001B[0m26.55\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 1)\n----- TRAINING - EPOCH 2 -----\nLEARNING RATE:  0.00045476628804148113\nloss: 1.064 (epoch: 2, step: 0) // Avg time/img: 0.1171 s\nloss: 0.7339 (epoch: 2, step: 50) // Avg time/img: 0.0720 s\nloss: 0.6811 (epoch: 2, step: 100) // Avg time/img: 0.0708 s\nloss: 0.6662 (epoch: 2, step: 150) // Avg time/img: 0.0706 s\nloss: 0.6823 (epoch: 2, step: 200) // Avg time/img: 0.0705 s\nloss: 0.6955 (epoch: 2, step: 250) // Avg time/img: 0.0704 s\nloss: 0.6727 (epoch: 2, step: 300) // Avg time/img: 0.0707 s\nloss: 0.6613 (epoch: 2, step: 350) // Avg time/img: 0.0706 s\nloss: 0.6675 (epoch: 2, step: 400) // Avg time/img: 0.0705 s\nloss: 0.6669 (epoch: 2, step: 450) // Avg time/img: 0.0704 s\nloss: 0.6652 (epoch: 2, step: 500) // Avg time/img: 0.0704 s\nloss: 0.6561 (epoch: 2, step: 550) // Avg time/img: 0.0703 s\nloss: 0.6591 (epoch: 2, step: 600) // Avg time/img: 0.0703 s\nloss: 0.653 (epoch: 2, step: 650) // Avg time/img: 0.0703 s\nloss: 0.6529 (epoch: 2, step: 700) // Avg time/img: 0.0703 s\nloss: 0.6515 (epoch: 2, step: 750) // Avg time/img: 0.0704 s\nloss: 0.6533 (epoch: 2, step: 800) // Avg time/img: 0.0704 s\nloss: 0.6534 (epoch: 2, step: 850) // Avg time/img: 0.0703 s\nloss: 0.6561 (epoch: 2, step: 900) // Avg time/img: 0.0703 s\nloss: 0.6543 (epoch: 2, step: 950) // Avg time/img: 0.0703 s\nloss: 0.6516 (epoch: 2, step: 1000) // Avg time/img: 0.0702 s\nloss: 0.6506 (epoch: 2, step: 1050) // Avg time/img: 0.0702 s\nloss: 0.6509 (epoch: 2, step: 1100) // Avg time/img: 0.0702 s\nloss: 0.6475 (epoch: 2, step: 1150) // Avg time/img: 0.0703 s\nloss: 0.6434 (epoch: 2, step: 1200) // Avg time/img: 0.0702 s\nloss: 0.6416 (epoch: 2, step: 1250) // Avg time/img: 0.0702 s\nloss: 0.6404 (epoch: 2, step: 1300) // Avg time/img: 0.0702 s\nloss: 0.6427 (epoch: 2, step: 1350) // Avg time/img: 0.0702 s\nloss: 0.6408 (epoch: 2, step: 1400) // Avg time/img: 0.0702 s\nloss: 0.6427 (epoch: 2, step: 1450) // Avg time/img: 0.0702 s\nloss: 0.6444 (epoch: 2, step: 1500) // Avg time/img: 0.0702 s\nloss: 0.6422 (epoch: 2, step: 1550) // Avg time/img: 0.0702 s\nloss: 0.6405 (epoch: 2, step: 1600) // Avg time/img: 0.0702 s\nloss: 0.6379 (epoch: 2, step: 1650) // Avg time/img: 0.0702 s\nloss: 0.6343 (epoch: 2, step: 1700) // Avg time/img: 0.0702 s\nloss: 0.6318 (epoch: 2, step: 1750) // Avg time/img: 0.0702 s\nloss: 0.6283 (epoch: 2, step: 1800) // Avg time/img: 0.0702 s\nloss: 0.626 (epoch: 2, step: 1850) // Avg time/img: 0.0702 s\nloss: 0.6235 (epoch: 2, step: 1900) // Avg time/img: 0.0702 s\nloss: 0.622 (epoch: 2, step: 1950) // Avg time/img: 0.0701 s\nloss: 0.6242 (epoch: 2, step: 2000) // Avg time/img: 0.0702 s\nloss: 0.6233 (epoch: 2, step: 2050) // Avg time/img: 0.0702 s\nloss: 0.622 (epoch: 2, step: 2100) // Avg time/img: 0.0702 s\nloss: 0.6223 (epoch: 2, step: 2150) // Avg time/img: 0.0702 s\nloss: 0.6222 (epoch: 2, step: 2200) // Avg time/img: 0.0702 s\nloss: 0.6221 (epoch: 2, step: 2250) // Avg time/img: 0.0702 s\nloss: 0.621 (epoch: 2, step: 2300) // Avg time/img: 0.0702 s\nloss: 0.6199 (epoch: 2, step: 2350) // Avg time/img: 0.0701 s\nloss: 0.6187 (epoch: 2, step: 2400) // Avg time/img: 0.0702 s\nloss: 0.6187 (epoch: 2, step: 2450) // Avg time/img: 0.0702 s\nloss: 0.6176 (epoch: 2, step: 2500) // Avg time/img: 0.0702 s\nloss: 0.6176 (epoch: 2, step: 2550) // Avg time/img: 0.0702 s\nloss: 0.619 (epoch: 2, step: 2600) // Avg time/img: 0.0702 s\nloss: 0.6189 (epoch: 2, step: 2650) // Avg time/img: 0.0702 s\nloss: 0.6193 (epoch: 2, step: 2700) // Avg time/img: 0.0702 s\nloss: 0.6201 (epoch: 2, step: 2750) // Avg time/img: 0.0701 s\nloss: 0.6201 (epoch: 2, step: 2800) // Avg time/img: 0.0701 s\nloss: 0.6191 (epoch: 2, step: 2850) // Avg time/img: 0.0702 s\nloss: 0.6195 (epoch: 2, step: 2900) // Avg time/img: 0.0702 s\nloss: 0.6185 (epoch: 2, step: 2950) // Avg time/img: 0.0702 s\n----- VALIDATING - EPOCH 2 -----\nVAL loss: 0.5888 (epoch: 2, step: 0) // Avg time/img: 0.0522 s\nVAL loss: 0.669 (epoch: 2, step: 50) // Avg time/img: 0.0265 s\nVAL loss: 0.7723 (epoch: 2, step: 100) // Avg time/img: 0.0262 s\nVAL loss: 0.7713 (epoch: 2, step: 150) // Avg time/img: 0.0261 s\nVAL loss: 0.7616 (epoch: 2, step: 200) // Avg time/img: 0.0261 s\nVAL loss: 0.7401 (epoch: 2, step: 250) // Avg time/img: 0.0262 s\nVAL loss: 0.7485 (epoch: 2, step: 300) // Avg time/img: 0.0260 s\nVAL loss: 0.7426 (epoch: 2, step: 350) // Avg time/img: 0.0260 s\nVAL loss: 0.7172 (epoch: 2, step: 400) // Avg time/img: 0.0260 s\nVAL loss: 0.6867 (epoch: 2, step: 450) // Avg time/img: 0.0260 s\nEPOCH IoU on VAL set:  \u001B[0m32.61\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 2)\n----- TRAINING - EPOCH 3 -----\nLEARNING RATE:  0.00040902607302542923\nloss: 0.463 (epoch: 3, step: 0) // Avg time/img: 0.1183 s\nloss: 0.5581 (epoch: 3, step: 50) // Avg time/img: 0.0757 s\nloss: 0.5175 (epoch: 3, step: 100) // Avg time/img: 0.0730 s\nloss: 0.514 (epoch: 3, step: 150) // Avg time/img: 0.0720 s\nloss: 0.5298 (epoch: 3, step: 200) // Avg time/img: 0.0716 s\nloss: 0.5444 (epoch: 3, step: 250) // Avg time/img: 0.0712 s\nloss: 0.5329 (epoch: 3, step: 300) // Avg time/img: 0.0710 s\nloss: 0.547 (epoch: 3, step: 350) // Avg time/img: 0.0709 s\nloss: 0.5551 (epoch: 3, step: 400) // Avg time/img: 0.0708 s\nloss: 0.561 (epoch: 3, step: 450) // Avg time/img: 0.0710 s\nloss: 0.5552 (epoch: 3, step: 500) // Avg time/img: 0.0709 s\nloss: 0.5572 (epoch: 3, step: 550) // Avg time/img: 0.0708 s\nloss: 0.5565 (epoch: 3, step: 600) // Avg time/img: 0.0707 s\nloss: 0.555 (epoch: 3, step: 650) // Avg time/img: 0.0706 s\nloss: 0.5574 (epoch: 3, step: 700) // Avg time/img: 0.0706 s\nloss: 0.5594 (epoch: 3, step: 750) // Avg time/img: 0.0705 s\nloss: 0.5621 (epoch: 3, step: 800) // Avg time/img: 0.0705 s\nloss: 0.5601 (epoch: 3, step: 850) // Avg time/img: 0.0705 s\nloss: 0.5575 (epoch: 3, step: 900) // Avg time/img: 0.0706 s\nloss: 0.5555 (epoch: 3, step: 950) // Avg time/img: 0.0706 s\nloss: 0.5543 (epoch: 3, step: 1000) // Avg time/img: 0.0705 s\nloss: 0.5548 (epoch: 3, step: 1050) // Avg time/img: 0.0705 s\nloss: 0.5551 (epoch: 3, step: 1100) // Avg time/img: 0.0705 s\nloss: 0.5541 (epoch: 3, step: 1150) // Avg time/img: 0.0704 s\nloss: 0.552 (epoch: 3, step: 1200) // Avg time/img: 0.0704 s\nloss: 0.5482 (epoch: 3, step: 1250) // Avg time/img: 0.0704 s\nloss: 0.548 (epoch: 3, step: 1300) // Avg time/img: 0.0705 s\nloss: 0.5454 (epoch: 3, step: 1350) // Avg time/img: 0.0705 s\nloss: 0.5407 (epoch: 3, step: 1400) // Avg time/img: 0.0705 s\nloss: 0.5421 (epoch: 3, step: 1450) // Avg time/img: 0.0704 s\nloss: 0.5423 (epoch: 3, step: 1500) // Avg time/img: 0.0704 s\nloss: 0.5407 (epoch: 3, step: 1550) // Avg time/img: 0.0704 s\nloss: 0.5404 (epoch: 3, step: 1600) // Avg time/img: 0.0704 s\nloss: 0.5389 (epoch: 3, step: 1650) // Avg time/img: 0.0704 s\nloss: 0.5365 (epoch: 3, step: 1700) // Avg time/img: 0.0704 s\nloss: 0.5358 (epoch: 3, step: 1750) // Avg time/img: 0.0704 s\nloss: 0.5341 (epoch: 3, step: 1800) // Avg time/img: 0.0704 s\nloss: 0.5332 (epoch: 3, step: 1850) // Avg time/img: 0.0704 s\nloss: 0.5334 (epoch: 3, step: 1900) // Avg time/img: 0.0704 s\nloss: 0.5336 (epoch: 3, step: 1950) // Avg time/img: 0.0704 s\nloss: 0.5345 (epoch: 3, step: 2000) // Avg time/img: 0.0704 s\nloss: 0.5339 (epoch: 3, step: 2050) // Avg time/img: 0.0704 s\nloss: 0.5336 (epoch: 3, step: 2100) // Avg time/img: 0.0703 s\nloss: 0.534 (epoch: 3, step: 2150) // Avg time/img: 0.0704 s\nloss: 0.5344 (epoch: 3, step: 2200) // Avg time/img: 0.0704 s\nloss: 0.5353 (epoch: 3, step: 2250) // Avg time/img: 0.0703 s\nloss: 0.5368 (epoch: 3, step: 2300) // Avg time/img: 0.0703 s\nloss: 0.5378 (epoch: 3, step: 2350) // Avg time/img: 0.0703 s\nloss: 0.5408 (epoch: 3, step: 2400) // Avg time/img: 0.0703 s\nloss: 0.5403 (epoch: 3, step: 2450) // Avg time/img: 0.0703 s\nloss: 0.5391 (epoch: 3, step: 2500) // Avg time/img: 0.0703 s\nloss: 0.5383 (epoch: 3, step: 2550) // Avg time/img: 0.0703 s\nloss: 0.5385 (epoch: 3, step: 2600) // Avg time/img: 0.0703 s\nloss: 0.5374 (epoch: 3, step: 2650) // Avg time/img: 0.0703 s\nloss: 0.5408 (epoch: 3, step: 2700) // Avg time/img: 0.0703 s\nloss: 0.5409 (epoch: 3, step: 2750) // Avg time/img: 0.0703 s\nloss: 0.5397 (epoch: 3, step: 2800) // Avg time/img: 0.0703 s\nloss: 0.5383 (epoch: 3, step: 2850) // Avg time/img: 0.0703 s\nloss: 0.5369 (epoch: 3, step: 2900) // Avg time/img: 0.0703 s\nloss: 0.5369 (epoch: 3, step: 2950) // Avg time/img: 0.0703 s\n----- VALIDATING - EPOCH 3 -----\nVAL loss: 0.4646 (epoch: 3, step: 0) // Avg time/img: 0.0581 s\nVAL loss: 0.5943 (epoch: 3, step: 50) // Avg time/img: 0.0258 s\nVAL loss: 0.7138 (epoch: 3, step: 100) // Avg time/img: 0.0259 s\nVAL loss: 0.7034 (epoch: 3, step: 150) // Avg time/img: 0.0259 s\nVAL loss: 0.7113 (epoch: 3, step: 200) // Avg time/img: 0.0258 s\nVAL loss: 0.6908 (epoch: 3, step: 250) // Avg time/img: 0.0259 s\nVAL loss: 0.6849 (epoch: 3, step: 300) // Avg time/img: 0.0259 s\nVAL loss: 0.6705 (epoch: 3, step: 350) // Avg time/img: 0.0258 s\nVAL loss: 0.6423 (epoch: 3, step: 400) // Avg time/img: 0.0258 s\nVAL loss: 0.6126 (epoch: 3, step: 450) // Avg time/img: 0.0258 s\nEPOCH IoU on VAL set:  \u001B[0m35.79\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 3)\n----- TRAINING - EPOCH 4 -----\nLEARNING RATE:  0.00036270892346860996\nloss: 0.3236 (epoch: 4, step: 0) // Avg time/img: 0.1234 s\nloss: 0.4661 (epoch: 4, step: 50) // Avg time/img: 0.0719 s\nloss: 0.4935 (epoch: 4, step: 100) // Avg time/img: 0.0715 s\nloss: 0.4877 (epoch: 4, step: 150) // Avg time/img: 0.0711 s\nloss: 0.4726 (epoch: 4, step: 200) // Avg time/img: 0.0715 s\nloss: 0.4681 (epoch: 4, step: 250) // Avg time/img: 0.0714 s\nloss: 0.473 (epoch: 4, step: 300) // Avg time/img: 0.0712 s\nloss: 0.4741 (epoch: 4, step: 350) // Avg time/img: 0.0711 s\nloss: 0.4798 (epoch: 4, step: 400) // Avg time/img: 0.0711 s\nloss: 0.483 (epoch: 4, step: 450) // Avg time/img: 0.0709 s\nloss: 0.4857 (epoch: 4, step: 500) // Avg time/img: 0.0709 s\nloss: 0.4902 (epoch: 4, step: 550) // Avg time/img: 0.0708 s\nloss: 0.4865 (epoch: 4, step: 600) // Avg time/img: 0.0710 s\nloss: 0.4845 (epoch: 4, step: 650) // Avg time/img: 0.0710 s\nloss: 0.4907 (epoch: 4, step: 700) // Avg time/img: 0.0709 s\nloss: 0.4916 (epoch: 4, step: 750) // Avg time/img: 0.0709 s\nloss: 0.4894 (epoch: 4, step: 800) // Avg time/img: 0.0709 s\nloss: 0.4924 (epoch: 4, step: 850) // Avg time/img: 0.0709 s\nloss: 0.4936 (epoch: 4, step: 900) // Avg time/img: 0.0708 s\nloss: 0.493 (epoch: 4, step: 950) // Avg time/img: 0.0708 s\nloss: 0.4931 (epoch: 4, step: 1000) // Avg time/img: 0.0709 s\nloss: 0.4933 (epoch: 4, step: 1050) // Avg time/img: 0.0709 s\nloss: 0.4919 (epoch: 4, step: 1100) // Avg time/img: 0.0709 s\nloss: 0.4933 (epoch: 4, step: 1150) // Avg time/img: 0.0709 s\nloss: 0.494 (epoch: 4, step: 1200) // Avg time/img: 0.0709 s\nloss: 0.4939 (epoch: 4, step: 1250) // Avg time/img: 0.0708 s\nloss: 0.4942 (epoch: 4, step: 1300) // Avg time/img: 0.0708 s\nloss: 0.4976 (epoch: 4, step: 1350) // Avg time/img: 0.0708 s\nloss: 0.4959 (epoch: 4, step: 1400) // Avg time/img: 0.0708 s\nloss: 0.4952 (epoch: 4, step: 1450) // Avg time/img: 0.0709 s\nloss: 0.4945 (epoch: 4, step: 1500) // Avg time/img: 0.0709 s\nloss: 0.4936 (epoch: 4, step: 1550) // Avg time/img: 0.0708 s\nloss: 0.4952 (epoch: 4, step: 1600) // Avg time/img: 0.0708 s\nloss: 0.494 (epoch: 4, step: 1650) // Avg time/img: 0.0708 s\nloss: 0.4937 (epoch: 4, step: 1700) // Avg time/img: 0.0708 s\nloss: 0.4922 (epoch: 4, step: 1750) // Avg time/img: 0.0708 s\nloss: 0.4919 (epoch: 4, step: 1800) // Avg time/img: 0.0708 s\nloss: 0.4915 (epoch: 4, step: 1850) // Avg time/img: 0.0708 s\nloss: 0.4905 (epoch: 4, step: 1900) // Avg time/img: 0.0708 s\nloss: 0.4908 (epoch: 4, step: 1950) // Avg time/img: 0.0708 s\nloss: 0.4924 (epoch: 4, step: 2000) // Avg time/img: 0.0708 s\nloss: 0.4922 (epoch: 4, step: 2050) // Avg time/img: 0.0708 s\nloss: 0.4918 (epoch: 4, step: 2100) // Avg time/img: 0.0708 s\nloss: 0.4915 (epoch: 4, step: 2150) // Avg time/img: 0.0708 s\nloss: 0.493 (epoch: 4, step: 2200) // Avg time/img: 0.0707 s\nloss: 0.4937 (epoch: 4, step: 2250) // Avg time/img: 0.0708 s\nloss: 0.4929 (epoch: 4, step: 2300) // Avg time/img: 0.0708 s\nloss: 0.4922 (epoch: 4, step: 2350) // Avg time/img: 0.0708 s\nloss: 0.4915 (epoch: 4, step: 2400) // Avg time/img: 0.0708 s\nloss: 0.4902 (epoch: 4, step: 2450) // Avg time/img: 0.0708 s\nloss: 0.4897 (epoch: 4, step: 2500) // Avg time/img: 0.0708 s\nloss: 0.4893 (epoch: 4, step: 2550) // Avg time/img: 0.0708 s\nloss: 0.4912 (epoch: 4, step: 2600) // Avg time/img: 0.0708 s\nloss: 0.4901 (epoch: 4, step: 2650) // Avg time/img: 0.0708 s\nloss: 0.4903 (epoch: 4, step: 2700) // Avg time/img: 0.0708 s\nloss: 0.4912 (epoch: 4, step: 2750) // Avg time/img: 0.0708 s\nloss: 0.4919 (epoch: 4, step: 2800) // Avg time/img: 0.0708 s\nloss: 0.4921 (epoch: 4, step: 2850) // Avg time/img: 0.0708 s\nloss: 0.4913 (epoch: 4, step: 2900) // Avg time/img: 0.0708 s\nloss: 0.4909 (epoch: 4, step: 2950) // Avg time/img: 0.0708 s\n----- VALIDATING - EPOCH 4 -----\nVAL loss: 0.5428 (epoch: 4, step: 0) // Avg time/img: 0.0536 s\nVAL loss: 0.6131 (epoch: 4, step: 50) // Avg time/img: 0.0263 s\nVAL loss: 0.6975 (epoch: 4, step: 100) // Avg time/img: 0.0265 s\nVAL loss: 0.6856 (epoch: 4, step: 150) // Avg time/img: 0.0263 s\nVAL loss: 0.673 (epoch: 4, step: 200) // Avg time/img: 0.0262 s\nVAL loss: 0.6532 (epoch: 4, step: 250) // Avg time/img: 0.0261 s\nVAL loss: 0.7055 (epoch: 4, step: 300) // Avg time/img: 0.0261 s\nVAL loss: 0.7212 (epoch: 4, step: 350) // Avg time/img: 0.0261 s\nVAL loss: 0.6833 (epoch: 4, step: 400) // Avg time/img: 0.0262 s\nVAL loss: 0.647 (epoch: 4, step: 450) // Avg time/img: 0.0262 s\nEPOCH IoU on VAL set:  \u001B[0m35.65\u001B[0m %\n----- TRAINING - EPOCH 5 -----\nLEARNING RATE:  0.00031572293374467766\nloss: 0.4275 (epoch: 5, step: 0) // Avg time/img: 0.1233 s\nloss: 0.4202 (epoch: 5, step: 50) // Avg time/img: 0.0731 s\nloss: 0.4339 (epoch: 5, step: 100) // Avg time/img: 0.0726 s\nloss: 0.4395 (epoch: 5, step: 150) // Avg time/img: 0.0721 s\nloss: 0.4365 (epoch: 5, step: 200) // Avg time/img: 0.0718 s\nloss: 0.4372 (epoch: 5, step: 250) // Avg time/img: 0.0718 s\nloss: 0.4438 (epoch: 5, step: 300) // Avg time/img: 0.0723 s\nloss: 0.446 (epoch: 5, step: 350) // Avg time/img: 0.0722 s\nloss: 0.4497 (epoch: 5, step: 400) // Avg time/img: 0.0721 s\nloss: 0.4539 (epoch: 5, step: 450) // Avg time/img: 0.0720 s\nloss: 0.4558 (epoch: 5, step: 500) // Avg time/img: 0.0720 s\nloss: 0.4513 (epoch: 5, step: 550) // Avg time/img: 0.0719 s\nloss: 0.4482 (epoch: 5, step: 600) // Avg time/img: 0.0719 s\nloss: 0.4474 (epoch: 5, step: 650) // Avg time/img: 0.0719 s\nloss: 0.4466 (epoch: 5, step: 700) // Avg time/img: 0.0720 s\nloss: 0.4475 (epoch: 5, step: 750) // Avg time/img: 0.0720 s\nloss: 0.4506 (epoch: 5, step: 800) // Avg time/img: 0.0720 s\nloss: 0.4511 (epoch: 5, step: 850) // Avg time/img: 0.0720 s\nloss: 0.4552 (epoch: 5, step: 900) // Avg time/img: 0.0720 s\nloss: 0.4542 (epoch: 5, step: 950) // Avg time/img: 0.0719 s\nloss: 0.4558 (epoch: 5, step: 1000) // Avg time/img: 0.0719 s\nloss: 0.4558 (epoch: 5, step: 1050) // Avg time/img: 0.0719 s\nloss: 0.4543 (epoch: 5, step: 1100) // Avg time/img: 0.0719 s\nloss: 0.4541 (epoch: 5, step: 1150) // Avg time/img: 0.0719 s\nloss: 0.4567 (epoch: 5, step: 1200) // Avg time/img: 0.0719 s\nloss: 0.4567 (epoch: 5, step: 1250) // Avg time/img: 0.0719 s\nloss: 0.4616 (epoch: 5, step: 1300) // Avg time/img: 0.0719 s\nloss: 0.4608 (epoch: 5, step: 1350) // Avg time/img: 0.0718 s\nloss: 0.46 (epoch: 5, step: 1400) // Avg time/img: 0.0718 s\nloss: 0.4593 (epoch: 5, step: 1450) // Avg time/img: 0.0718 s\nloss: 0.46 (epoch: 5, step: 1500) // Avg time/img: 0.0718 s\nloss: 0.4579 (epoch: 5, step: 1550) // Avg time/img: 0.0719 s\nloss: 0.4581 (epoch: 5, step: 1600) // Avg time/img: 0.0719 s\nloss: 0.4574 (epoch: 5, step: 1650) // Avg time/img: 0.0719 s\nloss: 0.4569 (epoch: 5, step: 1700) // Avg time/img: 0.0719 s\nloss: 0.4568 (epoch: 5, step: 1750) // Avg time/img: 0.0719 s\nloss: 0.4584 (epoch: 5, step: 1800) // Avg time/img: 0.0719 s\nloss: 0.4592 (epoch: 5, step: 1850) // Avg time/img: 0.0719 s\nloss: 0.4592 (epoch: 5, step: 1900) // Avg time/img: 0.0719 s\nloss: 0.4585 (epoch: 5, step: 1950) // Avg time/img: 0.0719 s\nloss: 0.4585 (epoch: 5, step: 2000) // Avg time/img: 0.0719 s\nloss: 0.4576 (epoch: 5, step: 2050) // Avg time/img: 0.0719 s\nloss: 0.4564 (epoch: 5, step: 2100) // Avg time/img: 0.0719 s\nloss: 0.4564 (epoch: 5, step: 2150) // Avg time/img: 0.0719 s\nloss: 0.4564 (epoch: 5, step: 2200) // Avg time/img: 0.0719 s\nloss: 0.4558 (epoch: 5, step: 2250) // Avg time/img: 0.0719 s\nloss: 0.4556 (epoch: 5, step: 2300) // Avg time/img: 0.0719 s\nloss: 0.4563 (epoch: 5, step: 2350) // Avg time/img: 0.0719 s\nloss: 0.4566 (epoch: 5, step: 2400) // Avg time/img: 0.0719 s\nloss: 0.4591 (epoch: 5, step: 2450) // Avg time/img: 0.0719 s\nloss: 0.4573 (epoch: 5, step: 2500) // Avg time/img: 0.0719 s\nloss: 0.457 (epoch: 5, step: 2550) // Avg time/img: 0.0719 s\nloss: 0.4561 (epoch: 5, step: 2600) // Avg time/img: 0.0719 s\nloss: 0.4561 (epoch: 5, step: 2650) // Avg time/img: 0.0719 s\nloss: 0.4559 (epoch: 5, step: 2700) // Avg time/img: 0.0719 s\nloss: 0.4569 (epoch: 5, step: 2750) // Avg time/img: 0.0719 s\nloss: 0.4565 (epoch: 5, step: 2800) // Avg time/img: 0.0719 s\nloss: 0.4563 (epoch: 5, step: 2850) // Avg time/img: 0.0719 s\nloss: 0.4561 (epoch: 5, step: 2900) // Avg time/img: 0.0719 s\nloss: 0.4558 (epoch: 5, step: 2950) // Avg time/img: 0.0719 s\n----- VALIDATING - EPOCH 5 -----\nVAL loss: 0.594 (epoch: 5, step: 0) // Avg time/img: 0.0538 s\nVAL loss: 0.5403 (epoch: 5, step: 50) // Avg time/img: 0.0261 s\nVAL loss: 0.6533 (epoch: 5, step: 100) // Avg time/img: 0.0258 s\nVAL loss: 0.6425 (epoch: 5, step: 150) // Avg time/img: 0.0259 s\nVAL loss: 0.6394 (epoch: 5, step: 200) // Avg time/img: 0.0260 s\nVAL loss: 0.6258 (epoch: 5, step: 250) // Avg time/img: 0.0260 s\nVAL loss: 0.6241 (epoch: 5, step: 300) // Avg time/img: 0.0261 s\nVAL loss: 0.6171 (epoch: 5, step: 350) // Avg time/img: 0.0260 s\nVAL loss: 0.5872 (epoch: 5, step: 400) // Avg time/img: 0.0261 s\nVAL loss: 0.5578 (epoch: 5, step: 450) // Avg time/img: 0.0261 s\nEPOCH IoU on VAL set:  \u001B[0m38.04\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 5)\n----- TRAINING - EPOCH 6 -----\nLEARNING RATE:  0.0002679433656340733\nloss: 0.3456 (epoch: 6, step: 0) // Avg time/img: 0.0801 s\nloss: 0.4462 (epoch: 6, step: 50) // Avg time/img: 0.0709 s\nloss: 0.4381 (epoch: 6, step: 100) // Avg time/img: 0.0709 s\nloss: 0.4323 (epoch: 6, step: 150) // Avg time/img: 0.0707 s\nloss: 0.4177 (epoch: 6, step: 200) // Avg time/img: 0.0708 s\nloss: 0.4076 (epoch: 6, step: 250) // Avg time/img: 0.0706 s\nloss: 0.4021 (epoch: 6, step: 300) // Avg time/img: 0.0706 s\nloss: 0.4004 (epoch: 6, step: 350) // Avg time/img: 0.0708 s\nloss: 0.3995 (epoch: 6, step: 400) // Avg time/img: 0.0709 s\nloss: 0.3937 (epoch: 6, step: 450) // Avg time/img: 0.0708 s\nloss: 0.397 (epoch: 6, step: 500) // Avg time/img: 0.0708 s\nloss: 0.3976 (epoch: 6, step: 550) // Avg time/img: 0.0707 s\nloss: 0.4046 (epoch: 6, step: 600) // Avg time/img: 0.0707 s\nloss: 0.4074 (epoch: 6, step: 650) // Avg time/img: 0.0707 s\nloss: 0.4051 (epoch: 6, step: 700) // Avg time/img: 0.0706 s\nloss: 0.4051 (epoch: 6, step: 750) // Avg time/img: 0.0706 s\nloss: 0.4078 (epoch: 6, step: 800) // Avg time/img: 0.0708 s\nloss: 0.4077 (epoch: 6, step: 850) // Avg time/img: 0.0708 s\nloss: 0.409 (epoch: 6, step: 900) // Avg time/img: 0.0707 s\nloss: 0.4141 (epoch: 6, step: 950) // Avg time/img: 0.0707 s\nloss: 0.4137 (epoch: 6, step: 1000) // Avg time/img: 0.0707 s\nloss: 0.4151 (epoch: 6, step: 1050) // Avg time/img: 0.0707 s\nloss: 0.4157 (epoch: 6, step: 1100) // Avg time/img: 0.0706 s\nloss: 0.4169 (epoch: 6, step: 1150) // Avg time/img: 0.0706 s\nloss: 0.4182 (epoch: 6, step: 1200) // Avg time/img: 0.0707 s\nloss: 0.4191 (epoch: 6, step: 1250) // Avg time/img: 0.0707 s\nloss: 0.419 (epoch: 6, step: 1300) // Avg time/img: 0.0707 s\nloss: 0.418 (epoch: 6, step: 1350) // Avg time/img: 0.0707 s\nloss: 0.4199 (epoch: 6, step: 1400) // Avg time/img: 0.0707 s\nloss: 0.4196 (epoch: 6, step: 1450) // Avg time/img: 0.0707 s\nloss: 0.4212 (epoch: 6, step: 1500) // Avg time/img: 0.0706 s\nloss: 0.4199 (epoch: 6, step: 1550) // Avg time/img: 0.0707 s\nloss: 0.419 (epoch: 6, step: 1600) // Avg time/img: 0.0706 s\nloss: 0.417 (epoch: 6, step: 1650) // Avg time/img: 0.0707 s\nloss: 0.417 (epoch: 6, step: 1700) // Avg time/img: 0.0707 s\nloss: 0.4184 (epoch: 6, step: 1750) // Avg time/img: 0.0706 s\nloss: 0.418 (epoch: 6, step: 1800) // Avg time/img: 0.0707 s\nloss: 0.4169 (epoch: 6, step: 1850) // Avg time/img: 0.0706 s\nloss: 0.4172 (epoch: 6, step: 1900) // Avg time/img: 0.0706 s\nloss: 0.4161 (epoch: 6, step: 1950) // Avg time/img: 0.0706 s\nloss: 0.4162 (epoch: 6, step: 2000) // Avg time/img: 0.0706 s\nloss: 0.4175 (epoch: 6, step: 2050) // Avg time/img: 0.0707 s\nloss: 0.417 (epoch: 6, step: 2100) // Avg time/img: 0.0707 s\nloss: 0.4173 (epoch: 6, step: 2150) // Avg time/img: 0.0707 s\nloss: 0.418 (epoch: 6, step: 2200) // Avg time/img: 0.0707 s\nloss: 0.4184 (epoch: 6, step: 2250) // Avg time/img: 0.0707 s\nloss: 0.4188 (epoch: 6, step: 2300) // Avg time/img: 0.0707 s\nloss: 0.4174 (epoch: 6, step: 2350) // Avg time/img: 0.0707 s\nloss: 0.4172 (epoch: 6, step: 2400) // Avg time/img: 0.0707 s\nloss: 0.417 (epoch: 6, step: 2450) // Avg time/img: 0.0707 s\nloss: 0.4187 (epoch: 6, step: 2500) // Avg time/img: 0.0707 s\nloss: 0.4191 (epoch: 6, step: 2550) // Avg time/img: 0.0707 s\nloss: 0.419 (epoch: 6, step: 2600) // Avg time/img: 0.0707 s\nloss: 0.4187 (epoch: 6, step: 2650) // Avg time/img: 0.0707 s\nloss: 0.4188 (epoch: 6, step: 2700) // Avg time/img: 0.0707 s\nloss: 0.4182 (epoch: 6, step: 2750) // Avg time/img: 0.0707 s\nloss: 0.4183 (epoch: 6, step: 2800) // Avg time/img: 0.0707 s\nloss: 0.418 (epoch: 6, step: 2850) // Avg time/img: 0.0707 s\nloss: 0.4181 (epoch: 6, step: 2900) // Avg time/img: 0.0708 s\nloss: 0.4175 (epoch: 6, step: 2950) // Avg time/img: 0.0707 s\n----- VALIDATING - EPOCH 6 -----\nVAL loss: 0.6171 (epoch: 6, step: 0) // Avg time/img: 0.0536 s\nVAL loss: 0.5272 (epoch: 6, step: 50) // Avg time/img: 0.0259 s\nVAL loss: 0.6234 (epoch: 6, step: 100) // Avg time/img: 0.0257 s\nVAL loss: 0.6142 (epoch: 6, step: 150) // Avg time/img: 0.0258 s\nVAL loss: 0.6103 (epoch: 6, step: 200) // Avg time/img: 0.0258 s\nVAL loss: 0.592 (epoch: 6, step: 250) // Avg time/img: 0.0260 s\nVAL loss: 0.6248 (epoch: 6, step: 300) // Avg time/img: 0.0260 s\nVAL loss: 0.6396 (epoch: 6, step: 350) // Avg time/img: 0.0261 s\nVAL loss: 0.604 (epoch: 6, step: 400) // Avg time/img: 0.0261 s\nVAL loss: 0.5714 (epoch: 6, step: 450) // Avg time/img: 0.0261 s\nEPOCH IoU on VAL set:  \u001B[0m39.90\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 6)\n----- TRAINING - EPOCH 7 -----\nLEARNING RATE:  0.00021919164527704348\nloss: 0.5641 (epoch: 7, step: 0) // Avg time/img: 0.0831 s\nloss: 0.3699 (epoch: 7, step: 50) // Avg time/img: 0.0716 s\nloss: 0.3928 (epoch: 7, step: 100) // Avg time/img: 0.0719 s\nloss: 0.3868 (epoch: 7, step: 150) // Avg time/img: 0.0711 s\nloss: 0.3812 (epoch: 7, step: 200) // Avg time/img: 0.0708 s\nloss: 0.3795 (epoch: 7, step: 250) // Avg time/img: 0.0707 s\nloss: 0.3875 (epoch: 7, step: 300) // Avg time/img: 0.0706 s\nloss: 0.3866 (epoch: 7, step: 350) // Avg time/img: 0.0706 s\nloss: 0.3883 (epoch: 7, step: 400) // Avg time/img: 0.0705 s\nloss: 0.3892 (epoch: 7, step: 450) // Avg time/img: 0.0704 s\nloss: 0.3835 (epoch: 7, step: 500) // Avg time/img: 0.0707 s\nloss: 0.3871 (epoch: 7, step: 550) // Avg time/img: 0.0706 s\nloss: 0.3879 (epoch: 7, step: 600) // Avg time/img: 0.0706 s\nloss: 0.3884 (epoch: 7, step: 650) // Avg time/img: 0.0706 s\nloss: 0.3882 (epoch: 7, step: 700) // Avg time/img: 0.0706 s\nloss: 0.3858 (epoch: 7, step: 750) // Avg time/img: 0.0706 s\nloss: 0.3875 (epoch: 7, step: 800) // Avg time/img: 0.0705 s\nloss: 0.3896 (epoch: 7, step: 850) // Avg time/img: 0.0705 s\nloss: 0.3894 (epoch: 7, step: 900) // Avg time/img: 0.0705 s\nloss: 0.3898 (epoch: 7, step: 950) // Avg time/img: 0.0706 s\nloss: 0.3883 (epoch: 7, step: 1000) // Avg time/img: 0.0706 s\nloss: 0.3854 (epoch: 7, step: 1050) // Avg time/img: 0.0705 s\nloss: 0.3848 (epoch: 7, step: 1100) // Avg time/img: 0.0705 s\nloss: 0.3869 (epoch: 7, step: 1150) // Avg time/img: 0.0705 s\nloss: 0.3879 (epoch: 7, step: 1200) // Avg time/img: 0.0705 s\nloss: 0.3878 (epoch: 7, step: 1250) // Avg time/img: 0.0705 s\nloss: 0.3886 (epoch: 7, step: 1300) // Avg time/img: 0.0705 s\nloss: 0.3884 (epoch: 7, step: 1350) // Avg time/img: 0.0706 s\nloss: 0.3894 (epoch: 7, step: 1400) // Avg time/img: 0.0706 s\nloss: 0.3896 (epoch: 7, step: 1450) // Avg time/img: 0.0706 s\nloss: 0.3905 (epoch: 7, step: 1500) // Avg time/img: 0.0706 s\nloss: 0.3913 (epoch: 7, step: 1550) // Avg time/img: 0.0706 s\nloss: 0.3907 (epoch: 7, step: 1600) // Avg time/img: 0.0706 s\nloss: 0.3908 (epoch: 7, step: 1650) // Avg time/img: 0.0705 s\nloss: 0.3924 (epoch: 7, step: 1700) // Avg time/img: 0.0705 s\nloss: 0.3919 (epoch: 7, step: 1750) // Avg time/img: 0.0706 s\nloss: 0.3893 (epoch: 7, step: 1800) // Avg time/img: 0.0706 s\nloss: 0.3891 (epoch: 7, step: 1850) // Avg time/img: 0.0705 s\nloss: 0.3898 (epoch: 7, step: 1900) // Avg time/img: 0.0705 s\nloss: 0.3919 (epoch: 7, step: 1950) // Avg time/img: 0.0705 s\nloss: 0.3921 (epoch: 7, step: 2000) // Avg time/img: 0.0705 s\nloss: 0.3914 (epoch: 7, step: 2050) // Avg time/img: 0.0705 s\nloss: 0.3911 (epoch: 7, step: 2100) // Avg time/img: 0.0705 s\nloss: 0.3904 (epoch: 7, step: 2150) // Avg time/img: 0.0705 s\nloss: 0.3903 (epoch: 7, step: 2200) // Avg time/img: 0.0706 s\nloss: 0.3905 (epoch: 7, step: 2250) // Avg time/img: 0.0706 s\nloss: 0.3903 (epoch: 7, step: 2300) // Avg time/img: 0.0706 s\nloss: 0.3911 (epoch: 7, step: 2350) // Avg time/img: 0.0706 s\nloss: 0.3916 (epoch: 7, step: 2400) // Avg time/img: 0.0706 s\nloss: 0.3929 (epoch: 7, step: 2450) // Avg time/img: 0.0705 s\nloss: 0.3931 (epoch: 7, step: 2500) // Avg time/img: 0.0705 s\nloss: 0.3921 (epoch: 7, step: 2550) // Avg time/img: 0.0705 s\nloss: 0.3912 (epoch: 7, step: 2600) // Avg time/img: 0.0706 s\nloss: 0.3909 (epoch: 7, step: 2650) // Avg time/img: 0.0706 s\nloss: 0.3916 (epoch: 7, step: 2700) // Avg time/img: 0.0706 s\nloss: 0.3916 (epoch: 7, step: 2750) // Avg time/img: 0.0706 s\nloss: 0.3913 (epoch: 7, step: 2800) // Avg time/img: 0.0705 s\nloss: 0.3914 (epoch: 7, step: 2850) // Avg time/img: 0.0705 s\nloss: 0.3923 (epoch: 7, step: 2900) // Avg time/img: 0.0705 s\nloss: 0.3923 (epoch: 7, step: 2950) // Avg time/img: 0.0705 s\n----- VALIDATING - EPOCH 7 -----\nVAL loss: 0.6162 (epoch: 7, step: 0) // Avg time/img: 0.0533 s\nVAL loss: 0.4983 (epoch: 7, step: 50) // Avg time/img: 0.0259 s\nVAL loss: 0.5772 (epoch: 7, step: 100) // Avg time/img: 0.0259 s\nVAL loss: 0.5704 (epoch: 7, step: 150) // Avg time/img: 0.0259 s\nVAL loss: 0.5595 (epoch: 7, step: 200) // Avg time/img: 0.0259 s\nVAL loss: 0.5445 (epoch: 7, step: 250) // Avg time/img: 0.0258 s\nVAL loss: 0.5712 (epoch: 7, step: 300) // Avg time/img: 0.0259 s\nVAL loss: 0.5814 (epoch: 7, step: 350) // Avg time/img: 0.0259 s\nVAL loss: 0.5518 (epoch: 7, step: 400) // Avg time/img: 0.0259 s\nVAL loss: 0.5232 (epoch: 7, step: 450) // Avg time/img: 0.0259 s\nEPOCH IoU on VAL set:  \u001B[0m41.04\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 7)\n----- TRAINING - EPOCH 8 -----\nLEARNING RATE:  0.00016919173095082495\nloss: 0.3426 (epoch: 8, step: 0) // Avg time/img: 0.1164 s\nloss: 0.4519 (epoch: 8, step: 50) // Avg time/img: 0.0719 s\nloss: 0.4197 (epoch: 8, step: 100) // Avg time/img: 0.0714 s\nloss: 0.3953 (epoch: 8, step: 150) // Avg time/img: 0.0709 s\nloss: 0.3831 (epoch: 8, step: 200) // Avg time/img: 0.0709 s\nloss: 0.3773 (epoch: 8, step: 250) // Avg time/img: 0.0710 s\nloss: 0.3762 (epoch: 8, step: 300) // Avg time/img: 0.0708 s\nloss: 0.3795 (epoch: 8, step: 350) // Avg time/img: 0.0706 s\nloss: 0.381 (epoch: 8, step: 400) // Avg time/img: 0.0705 s\nloss: 0.3763 (epoch: 8, step: 450) // Avg time/img: 0.0705 s\nloss: 0.3744 (epoch: 8, step: 500) // Avg time/img: 0.0704 s\nloss: 0.3708 (epoch: 8, step: 550) // Avg time/img: 0.0704 s\nloss: 0.3725 (epoch: 8, step: 600) // Avg time/img: 0.0703 s\nloss: 0.3752 (epoch: 8, step: 650) // Avg time/img: 0.0705 s\nloss: 0.3752 (epoch: 8, step: 700) // Avg time/img: 0.0704 s\nloss: 0.3735 (epoch: 8, step: 750) // Avg time/img: 0.0704 s\nloss: 0.3722 (epoch: 8, step: 800) // Avg time/img: 0.0704 s\nloss: 0.3691 (epoch: 8, step: 850) // Avg time/img: 0.0703 s\nloss: 0.3672 (epoch: 8, step: 900) // Avg time/img: 0.0703 s\nloss: 0.3647 (epoch: 8, step: 950) // Avg time/img: 0.0702 s\nloss: 0.3628 (epoch: 8, step: 1000) // Avg time/img: 0.0702 s\nloss: 0.3626 (epoch: 8, step: 1050) // Avg time/img: 0.0703 s\nloss: 0.3613 (epoch: 8, step: 1100) // Avg time/img: 0.0703 s\nloss: 0.3618 (epoch: 8, step: 1150) // Avg time/img: 0.0702 s\nloss: 0.3643 (epoch: 8, step: 1200) // Avg time/img: 0.0702 s\nloss: 0.3641 (epoch: 8, step: 1250) // Avg time/img: 0.0702 s\nloss: 0.3642 (epoch: 8, step: 1300) // Avg time/img: 0.0702 s\nloss: 0.3639 (epoch: 8, step: 1350) // Avg time/img: 0.0702 s\nloss: 0.3624 (epoch: 8, step: 1400) // Avg time/img: 0.0701 s\nloss: 0.3638 (epoch: 8, step: 1450) // Avg time/img: 0.0701 s\nloss: 0.3621 (epoch: 8, step: 1500) // Avg time/img: 0.0702 s\nloss: 0.3612 (epoch: 8, step: 1550) // Avg time/img: 0.0702 s\nloss: 0.3632 (epoch: 8, step: 1600) // Avg time/img: 0.0702 s\nloss: 0.3646 (epoch: 8, step: 1650) // Avg time/img: 0.0701 s\nloss: 0.3642 (epoch: 8, step: 1700) // Avg time/img: 0.0702 s\nloss: 0.3652 (epoch: 8, step: 1750) // Avg time/img: 0.0701 s\nloss: 0.3659 (epoch: 8, step: 1800) // Avg time/img: 0.0701 s\nloss: 0.3655 (epoch: 8, step: 1850) // Avg time/img: 0.0701 s\nloss: 0.3645 (epoch: 8, step: 1900) // Avg time/img: 0.0701 s\nloss: 0.3644 (epoch: 8, step: 1950) // Avg time/img: 0.0702 s\nloss: 0.3646 (epoch: 8, step: 2000) // Avg time/img: 0.0702 s\nloss: 0.3664 (epoch: 8, step: 2050) // Avg time/img: 0.0701 s\nloss: 0.3678 (epoch: 8, step: 2100) // Avg time/img: 0.0701 s\nloss: 0.369 (epoch: 8, step: 2150) // Avg time/img: 0.0701 s\nloss: 0.368 (epoch: 8, step: 2200) // Avg time/img: 0.0701 s\nloss: 0.3674 (epoch: 8, step: 2250) // Avg time/img: 0.0701 s\nloss: 0.3666 (epoch: 8, step: 2300) // Avg time/img: 0.0701 s\nloss: 0.3659 (epoch: 8, step: 2350) // Avg time/img: 0.0701 s\nloss: 0.3655 (epoch: 8, step: 2400) // Avg time/img: 0.0701 s\nloss: 0.3656 (epoch: 8, step: 2450) // Avg time/img: 0.0701 s\nloss: 0.3657 (epoch: 8, step: 2500) // Avg time/img: 0.0701 s\nloss: 0.3641 (epoch: 8, step: 2550) // Avg time/img: 0.0701 s\nloss: 0.3641 (epoch: 8, step: 2600) // Avg time/img: 0.0701 s\nloss: 0.3644 (epoch: 8, step: 2650) // Avg time/img: 0.0701 s\nloss: 0.3647 (epoch: 8, step: 2700) // Avg time/img: 0.0701 s\nloss: 0.364 (epoch: 8, step: 2750) // Avg time/img: 0.0701 s\nloss: 0.3637 (epoch: 8, step: 2800) // Avg time/img: 0.0701 s\nloss: 0.3641 (epoch: 8, step: 2850) // Avg time/img: 0.0701 s\nloss: 0.3645 (epoch: 8, step: 2900) // Avg time/img: 0.0701 s\nloss: 0.3647 (epoch: 8, step: 2950) // Avg time/img: 0.0701 s\n----- VALIDATING - EPOCH 8 -----\nVAL loss: 0.7517 (epoch: 8, step: 0) // Avg time/img: 0.0277 s\nVAL loss: 0.4778 (epoch: 8, step: 50) // Avg time/img: 0.0254 s\nVAL loss: 0.552 (epoch: 8, step: 100) // Avg time/img: 0.0255 s\nVAL loss: 0.5531 (epoch: 8, step: 150) // Avg time/img: 0.0257 s\nVAL loss: 0.5482 (epoch: 8, step: 200) // Avg time/img: 0.0257 s\nVAL loss: 0.5344 (epoch: 8, step: 250) // Avg time/img: 0.0257 s\nVAL loss: 0.5599 (epoch: 8, step: 300) // Avg time/img: 0.0257 s\nVAL loss: 0.5682 (epoch: 8, step: 350) // Avg time/img: 0.0258 s\nVAL loss: 0.5387 (epoch: 8, step: 400) // Avg time/img: 0.0258 s\nVAL loss: 0.512 (epoch: 8, step: 450) // Avg time/img: 0.0258 s\nEPOCH IoU on VAL set:  \u001B[0m42.90\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 8)\n----- TRAINING - EPOCH 9 -----\nLEARNING RATE:  0.00011746189430880188\nloss: 0.4918 (epoch: 9, step: 0) // Avg time/img: 0.0811 s\nloss: 0.3458 (epoch: 9, step: 50) // Avg time/img: 0.0706 s\nloss: 0.3476 (epoch: 9, step: 100) // Avg time/img: 0.0700 s\nloss: 0.344 (epoch: 9, step: 150) // Avg time/img: 0.0701 s\nloss: 0.3479 (epoch: 9, step: 200) // Avg time/img: 0.0700 s\nloss: 0.3516 (epoch: 9, step: 250) // Avg time/img: 0.0699 s\nloss: 0.3408 (epoch: 9, step: 300) // Avg time/img: 0.0700 s\nloss: 0.3348 (epoch: 9, step: 350) // Avg time/img: 0.0702 s\nloss: 0.3343 (epoch: 9, step: 400) // Avg time/img: 0.0702 s\nloss: 0.3372 (epoch: 9, step: 450) // Avg time/img: 0.0702 s\nloss: 0.3368 (epoch: 9, step: 500) // Avg time/img: 0.0701 s\nloss: 0.3358 (epoch: 9, step: 550) // Avg time/img: 0.0701 s\nloss: 0.3374 (epoch: 9, step: 600) // Avg time/img: 0.0701 s\nloss: 0.3366 (epoch: 9, step: 650) // Avg time/img: 0.0701 s\nloss: 0.3369 (epoch: 9, step: 700) // Avg time/img: 0.0701 s\nloss: 0.3356 (epoch: 9, step: 750) // Avg time/img: 0.0700 s\nloss: 0.3333 (epoch: 9, step: 800) // Avg time/img: 0.0702 s\nloss: 0.3338 (epoch: 9, step: 850) // Avg time/img: 0.0702 s\nloss: 0.3346 (epoch: 9, step: 900) // Avg time/img: 0.0702 s\nloss: 0.3359 (epoch: 9, step: 950) // Avg time/img: 0.0702 s\nloss: 0.3343 (epoch: 9, step: 1000) // Avg time/img: 0.0701 s\nloss: 0.3371 (epoch: 9, step: 1050) // Avg time/img: 0.0701 s\nloss: 0.336 (epoch: 9, step: 1100) // Avg time/img: 0.0701 s\nloss: 0.3351 (epoch: 9, step: 1150) // Avg time/img: 0.0701 s\nloss: 0.3362 (epoch: 9, step: 1200) // Avg time/img: 0.0702 s\nloss: 0.3368 (epoch: 9, step: 1250) // Avg time/img: 0.0702 s\nloss: 0.3375 (epoch: 9, step: 1300) // Avg time/img: 0.0702 s\nloss: 0.3373 (epoch: 9, step: 1350) // Avg time/img: 0.0702 s\nloss: 0.3377 (epoch: 9, step: 1400) // Avg time/img: 0.0702 s\nloss: 0.3398 (epoch: 9, step: 1450) // Avg time/img: 0.0702 s\nloss: 0.3382 (epoch: 9, step: 1500) // Avg time/img: 0.0701 s\nloss: 0.3379 (epoch: 9, step: 1550) // Avg time/img: 0.0701 s\nloss: 0.3389 (epoch: 9, step: 1600) // Avg time/img: 0.0701 s\nloss: 0.3385 (epoch: 9, step: 1650) // Avg time/img: 0.0702 s\nloss: 0.3383 (epoch: 9, step: 1700) // Avg time/img: 0.0702 s\nloss: 0.3378 (epoch: 9, step: 1750) // Avg time/img: 0.0702 s\nloss: 0.3369 (epoch: 9, step: 1800) // Avg time/img: 0.0702 s\nloss: 0.3367 (epoch: 9, step: 1850) // Avg time/img: 0.0702 s\nloss: 0.3363 (epoch: 9, step: 1900) // Avg time/img: 0.0701 s\nloss: 0.3374 (epoch: 9, step: 1950) // Avg time/img: 0.0701 s\nloss: 0.3376 (epoch: 9, step: 2000) // Avg time/img: 0.0701 s\nloss: 0.3379 (epoch: 9, step: 2050) // Avg time/img: 0.0702 s\nloss: 0.3399 (epoch: 9, step: 2100) // Avg time/img: 0.0702 s\nloss: 0.3402 (epoch: 9, step: 2150) // Avg time/img: 0.0702 s\nloss: 0.3412 (epoch: 9, step: 2200) // Avg time/img: 0.0702 s\nloss: 0.3416 (epoch: 9, step: 2250) // Avg time/img: 0.0702 s\nloss: 0.3418 (epoch: 9, step: 2300) // Avg time/img: 0.0702 s\nloss: 0.3418 (epoch: 9, step: 2350) // Avg time/img: 0.0702 s\nloss: 0.3416 (epoch: 9, step: 2400) // Avg time/img: 0.0701 s\nloss: 0.3412 (epoch: 9, step: 2450) // Avg time/img: 0.0701 s\nloss: 0.3407 (epoch: 9, step: 2500) // Avg time/img: 0.0702 s\nloss: 0.3403 (epoch: 9, step: 2550) // Avg time/img: 0.0702 s\nloss: 0.3413 (epoch: 9, step: 2600) // Avg time/img: 0.0702 s\nloss: 0.3406 (epoch: 9, step: 2650) // Avg time/img: 0.0702 s\nloss: 0.3395 (epoch: 9, step: 2700) // Avg time/img: 0.0702 s\nloss: 0.3389 (epoch: 9, step: 2750) // Avg time/img: 0.0702 s\nloss: 0.3382 (epoch: 9, step: 2800) // Avg time/img: 0.0702 s\nloss: 0.3377 (epoch: 9, step: 2850) // Avg time/img: 0.0702 s\nloss: 0.3381 (epoch: 9, step: 2900) // Avg time/img: 0.0702 s\nloss: 0.3377 (epoch: 9, step: 2950) // Avg time/img: 0.0702 s\n----- VALIDATING - EPOCH 9 -----\nVAL loss: 0.8826 (epoch: 9, step: 0) // Avg time/img: 0.0288 s\nVAL loss: 0.494 (epoch: 9, step: 50) // Avg time/img: 0.0253 s\nVAL loss: 0.5662 (epoch: 9, step: 100) // Avg time/img: 0.0256 s\nVAL loss: 0.5602 (epoch: 9, step: 150) // Avg time/img: 0.0257 s\nVAL loss: 0.5578 (epoch: 9, step: 200) // Avg time/img: 0.0257 s\nVAL loss: 0.5448 (epoch: 9, step: 250) // Avg time/img: 0.0258 s\nVAL loss: 0.5727 (epoch: 9, step: 300) // Avg time/img: 0.0258 s\nVAL loss: 0.5808 (epoch: 9, step: 350) // Avg time/img: 0.0258 s\nVAL loss: 0.5514 (epoch: 9, step: 400) // Avg time/img: 0.0258 s\nVAL loss: 0.5211 (epoch: 9, step: 450) // Avg time/img: 0.0258 s\nEPOCH IoU on VAL set:  \u001B[0m44.06\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 9)\n----- TRAINING - EPOCH 10 -----\nLEARNING RATE:  6.294627058970836e-05\nloss: 0.2846 (epoch: 10, step: 0) // Avg time/img: 0.1179 s\nloss: 0.334 (epoch: 10, step: 50) // Avg time/img: 0.0738 s\nloss: 0.3143 (epoch: 10, step: 100) // Avg time/img: 0.0735 s\nloss: 0.3088 (epoch: 10, step: 150) // Avg time/img: 0.0726 s\nloss: 0.3183 (epoch: 10, step: 200) // Avg time/img: 0.0722 s\nloss: 0.316 (epoch: 10, step: 250) // Avg time/img: 0.0718 s\nloss: 0.3162 (epoch: 10, step: 300) // Avg time/img: 0.0717 s\nloss: 0.3111 (epoch: 10, step: 350) // Avg time/img: 0.0715 s\nloss: 0.3071 (epoch: 10, step: 400) // Avg time/img: 0.0715 s\nloss: 0.3085 (epoch: 10, step: 450) // Avg time/img: 0.0714 s\nloss: 0.3086 (epoch: 10, step: 500) // Avg time/img: 0.0717 s\nloss: 0.3076 (epoch: 10, step: 550) // Avg time/img: 0.0717 s\nloss: 0.3071 (epoch: 10, step: 600) // Avg time/img: 0.0716 s\nloss: 0.3069 (epoch: 10, step: 650) // Avg time/img: 0.0715 s\nloss: 0.3092 (epoch: 10, step: 700) // Avg time/img: 0.0715 s\nloss: 0.3125 (epoch: 10, step: 750) // Avg time/img: 0.0715 s\nloss: 0.3163 (epoch: 10, step: 800) // Avg time/img: 0.0715 s\nloss: 0.3171 (epoch: 10, step: 850) // Avg time/img: 0.0715 s\nloss: 0.3177 (epoch: 10, step: 900) // Avg time/img: 0.0716 s\nloss: 0.3171 (epoch: 10, step: 950) // Avg time/img: 0.0716 s\nloss: 0.3163 (epoch: 10, step: 1000) // Avg time/img: 0.0716 s\nloss: 0.3158 (epoch: 10, step: 1050) // Avg time/img: 0.0716 s\nloss: 0.3175 (epoch: 10, step: 1100) // Avg time/img: 0.0716 s\nloss: 0.3156 (epoch: 10, step: 1150) // Avg time/img: 0.0716 s\nloss: 0.3161 (epoch: 10, step: 1200) // Avg time/img: 0.0715 s\nloss: 0.3143 (epoch: 10, step: 1250) // Avg time/img: 0.0715 s\nloss: 0.3135 (epoch: 10, step: 1300) // Avg time/img: 0.0715 s\nloss: 0.3153 (epoch: 10, step: 1350) // Avg time/img: 0.0716 s\nloss: 0.3135 (epoch: 10, step: 1400) // Avg time/img: 0.0716 s\nloss: 0.3132 (epoch: 10, step: 1450) // Avg time/img: 0.0715 s\nloss: 0.3122 (epoch: 10, step: 1500) // Avg time/img: 0.0715 s\nloss: 0.3134 (epoch: 10, step: 1550) // Avg time/img: 0.0715 s\nloss: 0.3129 (epoch: 10, step: 1600) // Avg time/img: 0.0715 s\nloss: 0.3135 (epoch: 10, step: 1650) // Avg time/img: 0.0715 s\nloss: 0.3129 (epoch: 10, step: 1700) // Avg time/img: 0.0715 s\nloss: 0.3128 (epoch: 10, step: 1750) // Avg time/img: 0.0716 s\nloss: 0.3132 (epoch: 10, step: 1800) // Avg time/img: 0.0716 s\nloss: 0.3127 (epoch: 10, step: 1850) // Avg time/img: 0.0715 s\nloss: 0.3117 (epoch: 10, step: 1900) // Avg time/img: 0.0715 s\nloss: 0.3119 (epoch: 10, step: 1950) // Avg time/img: 0.0715 s\nloss: 0.3135 (epoch: 10, step: 2000) // Avg time/img: 0.0715 s\nloss: 0.3135 (epoch: 10, step: 2050) // Avg time/img: 0.0715 s\nloss: 0.3139 (epoch: 10, step: 2100) // Avg time/img: 0.0715 s\nloss: 0.3137 (epoch: 10, step: 2150) // Avg time/img: 0.0715 s\nloss: 0.3133 (epoch: 10, step: 2200) // Avg time/img: 0.0715 s\nloss: 0.313 (epoch: 10, step: 2250) // Avg time/img: 0.0715 s\nloss: 0.3126 (epoch: 10, step: 2300) // Avg time/img: 0.0715 s\nloss: 0.3127 (epoch: 10, step: 2350) // Avg time/img: 0.0715 s\nloss: 0.3129 (epoch: 10, step: 2400) // Avg time/img: 0.0715 s\nloss: 0.3127 (epoch: 10, step: 2450) // Avg time/img: 0.0715 s\nloss: 0.3129 (epoch: 10, step: 2500) // Avg time/img: 0.0715 s\nloss: 0.3131 (epoch: 10, step: 2550) // Avg time/img: 0.0715 s\nloss: 0.3131 (epoch: 10, step: 2600) // Avg time/img: 0.0715 s\nloss: 0.3127 (epoch: 10, step: 2650) // Avg time/img: 0.0715 s\nloss: 0.3127 (epoch: 10, step: 2700) // Avg time/img: 0.0715 s\nloss: 0.3132 (epoch: 10, step: 2750) // Avg time/img: 0.0715 s\nloss: 0.3146 (epoch: 10, step: 2800) // Avg time/img: 0.0715 s\nloss: 0.3144 (epoch: 10, step: 2850) // Avg time/img: 0.0715 s\nloss: 0.315 (epoch: 10, step: 2900) // Avg time/img: 0.0715 s\nloss: 0.316 (epoch: 10, step: 2950) // Avg time/img: 0.0715 s\n----- VALIDATING - EPOCH 10 -----\nVAL loss: 0.6405 (epoch: 10, step: 0) // Avg time/img: 0.0515 s\nVAL loss: 0.4489 (epoch: 10, step: 50) // Avg time/img: 0.0256 s\nVAL loss: 0.5004 (epoch: 10, step: 100) // Avg time/img: 0.0257 s\nVAL loss: 0.4952 (epoch: 10, step: 150) // Avg time/img: 0.0258 s\nVAL loss: 0.4991 (epoch: 10, step: 200) // Avg time/img: 0.0259 s\nVAL loss: 0.4902 (epoch: 10, step: 250) // Avg time/img: 0.0259 s\nVAL loss: 0.5482 (epoch: 10, step: 300) // Avg time/img: 0.0259 s\nVAL loss: 0.5604 (epoch: 10, step: 350) // Avg time/img: 0.0261 s\nVAL loss: 0.5275 (epoch: 10, step: 400) // Avg time/img: 0.0261 s\nVAL loss: 0.4981 (epoch: 10, step: 450) // Avg time/img: 0.0261 s\nEPOCH IoU on VAL set:  \u001B[0m45.67\u001B[0m %\nSaving model as best\nsave: ../save/erfnet_training1/model_best.pth (epoch: 10)\n========== TRAINING FINISHED ===========\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "## Convertitore Labels",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\n# python imports\nfrom __future__ import print_function, absolute_import, division\nimport os, glob, sys\n\n# cityscapes imports\nfrom cityscapesscripts.helpers.csHelpers import printError\nfrom cityscapesscripts.preparation.json2labelImg import json2labelImg\n\n# The main method\ndef main():\n    # Where to look for Cityscapes\n\n    cityscapesPath = \"/kaggle/input/cityscapes/Cityscape\"\n    # how to search for all ground truth\n    searchFine   = os.path.join( cityscapesPath , \"gtFine\"   , \"*\" , \"*\" , \"*_gt*_polygons.json\" )\n    searchCoarse = os.path.join( cityscapesPath , \"gtCoarse\" , \"*\" , \"*\" , \"*_gt*_polygons.json\" )\n\n    # search files\n    filesFine = glob.glob( searchFine )\n    filesFine.sort()\n    filesCoarse = glob.glob( searchCoarse )\n    filesCoarse.sort()\n\n    # concatenate fine and coarse\n    files = filesFine + filesCoarse\n    # files = filesFine # use this line if fine is enough for now.\n\n    # quit if we did not find anything\n    if not files:\n        printError( \"Did not find any files. Please consult the README.\" )\n\n    # a bit verbose\n    print(\"Processing {} annotation files\".format(len(files)))\n\n    # iterate through files\n    progress = 0\n    print(\"Progress: {:>3} %\".format( progress * 100 / len(files) ), end=' ')\n    for f in files:\n        # create the output filename\n        dst = f.replace( \"_polygons.json\" , \"_labelTrainIds.png\" )\n\n        # do the conversion\n        try:\n            json2labelImg( f , dst , \"trainIds\" )\n        except:\n            print(\"Failed to convert: {}\".format(f))\n            raise\n\n        # status\n        progress += 1\n        print(\"\\rProgress: {:>3} %\".format( progress * 100 / len(files) ), end=' ')\n        sys.stdout.flush()\n\n\n# call the main\nif __name__ == \"__main__\":\n    main()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Evaluation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Generates color images for visualization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!python3 \"/kaggle/working/AnomalySegmentation/eval/eval_cityscapes_color.py\" --datadir \"/kaggle/input/cityscapes-correctlabels/Cityscape\" --subset val --loadDir \"/kaggle/working/\" --loadWeights \"AnomalySegmentation/save/erfnet_training1/model_best.pth\" ",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### eval_iou",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!python  \"C:/Users/vcata\\Desktop\\Polito\\AML\\AnomalySegmentation\\eval/eval_iou.py\" --datadir \"C:/Users/vcata\\Desktop\\Polito\\AML\\proj\\BiSeNet\\datasets\\cityscapes\" --loadDir \"C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentation\" --loadWeights \"/trained_models/model_best_log_norm.pth\" --subset val",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-02T16:05:40.303708Z",
     "start_time": "2025-01-02T16:05:00.298622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentationerfnet.py\n",
      "Loading weights: C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentation/trained_models/model_best_log_norm.pth\n",
      "Model and weights LOADED successfully\n",
      "C:/Users/vcata\\Desktop\\Polito\\AML\\proj\\BiSeNet\\datasets\\cityscapes\\leftImg8bit/val C:/Users/vcata\\Desktop\\Polito\\AML\\proj\\BiSeNet\\datasets\\cityscapes\\gtFine/val\n",
      "0 val\\frankfurt\\frankfurt_000000_000294_leftImg8bit.png\n",
      "1 val\\frankfurt\\frankfurt_000000_000576_leftImg8bit.png\n",
      "2 val\\frankfurt\\frankfurt_000000_001016_leftImg8bit.png\n",
      "3 val\\frankfurt\\frankfurt_000000_001236_leftImg8bit.png\n",
      "4 val\\frankfurt\\frankfurt_000000_001751_leftImg8bit.png\n",
      "5 val\\frankfurt\\frankfurt_000000_002196_leftImg8bit.png\n",
      "6 val\\frankfurt\\frankfurt_000000_002963_leftImg8bit.png\n",
      "7 val\\frankfurt\\frankfurt_000000_003025_leftImg8bit.png\n",
      "8 val\\frankfurt\\frankfurt_000000_003357_leftImg8bit.png\n",
      "9 val\\frankfurt\\frankfurt_000000_003920_leftImg8bit.png\n",
      "10 val\\frankfurt\\frankfurt_000000_004617_leftImg8bit.png\n",
      "11 val\\frankfurt\\frankfurt_000000_005543_leftImg8bit.png\n",
      "12 val\\frankfurt\\frankfurt_000000_005898_leftImg8bit.png\n",
      "13 val\\frankfurt\\frankfurt_000000_006589_leftImg8bit.png\n",
      "14 val\\frankfurt\\frankfurt_000000_007365_leftImg8bit.png\n",
      "15 val\\frankfurt\\frankfurt_000000_008206_leftImg8bit.png\n",
      "16 val\\frankfurt\\frankfurt_000000_008451_leftImg8bit.png\n",
      "17 val\\frankfurt\\frankfurt_000000_009291_leftImg8bit.png\n",
      "18 val\\frankfurt\\frankfurt_000000_009561_leftImg8bit.png\n",
      "19 val\\frankfurt\\frankfurt_000000_009688_leftImg8bit.png\n",
      "20 val\\frankfurt\\frankfurt_000000_009969_leftImg8bit.png\n",
      "21 val\\frankfurt\\frankfurt_000000_010351_leftImg8bit.png\n",
      "22 val\\frankfurt\\frankfurt_000000_010763_leftImg8bit.png\n",
      "23 val\\frankfurt\\frankfurt_000000_011007_leftImg8bit.png\n",
      "24 val\\frankfurt\\frankfurt_000000_011074_leftImg8bit.png\n",
      "25 val\\frankfurt\\frankfurt_000000_011461_leftImg8bit.png\n",
      "26 val\\frankfurt\\frankfurt_000000_011810_leftImg8bit.png\n",
      "27 val\\frankfurt\\frankfurt_000000_012009_leftImg8bit.png\n",
      "28 val\\frankfurt\\frankfurt_000000_012121_leftImg8bit.png\n",
      "29 val\\frankfurt\\frankfurt_000000_012868_leftImg8bit.png\n",
      "30 val\\frankfurt\\frankfurt_000000_013067_leftImg8bit.png\n",
      "31 val\\frankfurt\\frankfurt_000000_013240_leftImg8bit.png\n",
      "32 val\\frankfurt\\frankfurt_000000_013382_leftImg8bit.png\n",
      "33 val\\frankfurt\\frankfurt_000000_013942_leftImg8bit.png\n",
      "34 val\\frankfurt\\frankfurt_000000_014480_leftImg8bit.png\n",
      "35 val\\frankfurt\\frankfurt_000000_015389_leftImg8bit.png\n",
      "36 val\\frankfurt\\frankfurt_000000_015676_leftImg8bit.png\n",
      "37 val\\frankfurt\\frankfurt_000000_016005_leftImg8bit.png\n",
      "38 val\\frankfurt\\frankfurt_000000_016286_leftImg8bit.png\n",
      "39 val\\frankfurt\\frankfurt_000000_017228_leftImg8bit.png\n",
      "40 val\\frankfurt\\frankfurt_000000_017476_leftImg8bit.png\n",
      "41 val\\frankfurt\\frankfurt_000000_018797_leftImg8bit.png\n",
      "42 val\\frankfurt\\frankfurt_000000_019607_leftImg8bit.png\n",
      "43 val\\frankfurt\\frankfurt_000000_020215_leftImg8bit.png\n",
      "44 val\\frankfurt\\frankfurt_000000_020321_leftImg8bit.png\n",
      "45 val\\frankfurt\\frankfurt_000000_020880_leftImg8bit.png\n",
      "46 val\\frankfurt\\frankfurt_000000_021667_leftImg8bit.png\n",
      "47 val\\frankfurt\\frankfurt_000000_021879_leftImg8bit.png\n",
      "48 val\\frankfurt\\frankfurt_000000_022254_leftImg8bit.png\n",
      "49 val\\frankfurt\\frankfurt_000000_022797_leftImg8bit.png\n",
      "50 val\\frankfurt\\frankfurt_000001_000538_leftImg8bit.png\n",
      "51 val\\frankfurt\\frankfurt_000001_001464_leftImg8bit.png\n",
      "52 val\\frankfurt\\frankfurt_000001_002512_leftImg8bit.png\n",
      "53 val\\frankfurt\\frankfurt_000001_002646_leftImg8bit.png\n",
      "54 val\\frankfurt\\frankfurt_000001_002759_leftImg8bit.png\n",
      "55 val\\frankfurt\\frankfurt_000001_003056_leftImg8bit.png\n",
      "56 val\\frankfurt\\frankfurt_000001_003588_leftImg8bit.png\n",
      "57 val\\frankfurt\\frankfurt_000001_004327_leftImg8bit.png\n",
      "58 val\\frankfurt\\frankfurt_000001_004736_leftImg8bit.png\n",
      "59 val\\frankfurt\\frankfurt_000001_004859_leftImg8bit.png\n",
      "60 val\\frankfurt\\frankfurt_000001_005184_leftImg8bit.png\n",
      "61 val\\frankfurt\\frankfurt_000001_005410_leftImg8bit.png\n",
      "62 val\\frankfurt\\frankfurt_000001_005703_leftImg8bit.png\n",
      "63 val\\frankfurt\\frankfurt_000001_005898_leftImg8bit.png\n",
      "64 val\\frankfurt\\frankfurt_000001_007285_leftImg8bit.png\n",
      "65 val\\frankfurt\\frankfurt_000001_007407_leftImg8bit.png\n",
      "66 val\\frankfurt\\frankfurt_000001_007622_leftImg8bit.png\n",
      "67 val\\frankfurt\\frankfurt_000001_007857_leftImg8bit.png\n",
      "68 val\\frankfurt\\frankfurt_000001_007973_leftImg8bit.png\n",
      "69 val\\frankfurt\\frankfurt_000001_008200_leftImg8bit.png\n",
      "70 val\\frankfurt\\frankfurt_000001_008688_leftImg8bit.png\n",
      "71 val\\frankfurt\\frankfurt_000001_009058_leftImg8bit.png\n",
      "72 val\\frankfurt\\frankfurt_000001_009504_leftImg8bit.png\n",
      "73 val\\frankfurt\\frankfurt_000001_009854_leftImg8bit.png\n",
      "74 val\\frankfurt\\frankfurt_000001_010156_leftImg8bit.png\n",
      "75 val\\frankfurt\\frankfurt_000001_010444_leftImg8bit.png\n",
      "76 val\\frankfurt\\frankfurt_000001_010600_leftImg8bit.png\n",
      "77 val\\frankfurt\\frankfurt_000001_010830_leftImg8bit.png\n",
      "78 val\\frankfurt\\frankfurt_000001_011162_leftImg8bit.png\n",
      "79 val\\frankfurt\\frankfurt_000001_011715_leftImg8bit.png\n",
      "80 val\\frankfurt\\frankfurt_000001_011835_leftImg8bit.png\n",
      "81 val\\frankfurt\\frankfurt_000001_012038_leftImg8bit.png\n",
      "82 val\\frankfurt\\frankfurt_000001_012519_leftImg8bit.png\n",
      "83 val\\frankfurt\\frankfurt_000001_012699_leftImg8bit.png\n",
      "84 val\\frankfurt\\frankfurt_000001_012738_leftImg8bit.png\n",
      "85 val\\frankfurt\\frankfurt_000001_012870_leftImg8bit.png\n",
      "86 val\\frankfurt\\frankfurt_000001_013016_leftImg8bit.png\n",
      "87 val\\frankfurt\\frankfurt_000001_013496_leftImg8bit.png\n",
      "88 val\\frankfurt\\frankfurt_000001_013710_leftImg8bit.png\n",
      "89 val\\frankfurt\\frankfurt_000001_014221_leftImg8bit.png\n",
      "90 val\\frankfurt\\frankfurt_000001_014406_leftImg8bit.png\n",
      "91 val\\frankfurt\\frankfurt_000001_014565_leftImg8bit.png\n",
      "92 val\\frankfurt\\frankfurt_000001_014741_leftImg8bit.png\n",
      "93 val\\frankfurt\\frankfurt_000001_015091_leftImg8bit.png\n",
      "94 val\\frankfurt\\frankfurt_000001_015328_leftImg8bit.png\n",
      "95 val\\frankfurt\\frankfurt_000001_015768_leftImg8bit.png\n",
      "96 val\\frankfurt\\frankfurt_000001_016029_leftImg8bit.png\n",
      "97 val\\frankfurt\\frankfurt_000001_016273_leftImg8bit.png\n",
      "98 val\\frankfurt\\frankfurt_000001_016462_leftImg8bit.png\n",
      "99 val\\frankfurt\\frankfurt_000001_017101_leftImg8bit.png\n",
      "100 val\\frankfurt\\frankfurt_000001_017459_leftImg8bit.png\n",
      "101 val\\frankfurt\\frankfurt_000001_017842_leftImg8bit.png\n",
      "102 val\\frankfurt\\frankfurt_000001_018113_leftImg8bit.png\n",
      "103 val\\frankfurt\\frankfurt_000001_019698_leftImg8bit.png\n",
      "104 val\\frankfurt\\frankfurt_000001_019854_leftImg8bit.png\n",
      "105 val\\frankfurt\\frankfurt_000001_019969_leftImg8bit.png\n",
      "106 val\\frankfurt\\frankfurt_000001_020046_leftImg8bit.png\n",
      "107 val\\frankfurt\\frankfurt_000001_020287_leftImg8bit.png\n",
      "108 val\\frankfurt\\frankfurt_000001_020693_leftImg8bit.png\n",
      "109 val\\frankfurt\\frankfurt_000001_021406_leftImg8bit.png\n",
      "110 val\\frankfurt\\frankfurt_000001_021825_leftImg8bit.png\n",
      "111 val\\frankfurt\\frankfurt_000001_023235_leftImg8bit.png\n",
      "112 val\\frankfurt\\frankfurt_000001_023369_leftImg8bit.png\n",
      "113 val\\frankfurt\\frankfurt_000001_023769_leftImg8bit.png\n",
      "114 val\\frankfurt\\frankfurt_000001_024927_leftImg8bit.png\n",
      "115 val\\frankfurt\\frankfurt_000001_025512_leftImg8bit.png\n",
      "116 val\\frankfurt\\frankfurt_000001_025713_leftImg8bit.png\n",
      "117 val\\frankfurt\\frankfurt_000001_025921_leftImg8bit.png\n",
      "118 val\\frankfurt\\frankfurt_000001_027325_leftImg8bit.png\n",
      "119 val\\frankfurt\\frankfurt_000001_028232_leftImg8bit.png\n",
      "120 val\\frankfurt\\frankfurt_000001_028335_leftImg8bit.png\n",
      "121 val\\frankfurt\\frankfurt_000001_028590_leftImg8bit.png\n",
      "122 val\\frankfurt\\frankfurt_000001_028854_leftImg8bit.png\n",
      "123 val\\frankfurt\\frankfurt_000001_029086_leftImg8bit.png\n",
      "124 val\\frankfurt\\frankfurt_000001_029236_leftImg8bit.png\n",
      "125 val\\frankfurt\\frankfurt_000001_029600_leftImg8bit.png\n",
      "126 val\\frankfurt\\frankfurt_000001_030067_leftImg8bit.png\n",
      "127 val\\frankfurt\\frankfurt_000001_030310_leftImg8bit.png\n",
      "128 val\\frankfurt\\frankfurt_000001_030669_leftImg8bit.png\n",
      "129 val\\frankfurt\\frankfurt_000001_031266_leftImg8bit.png\n",
      "130 val\\frankfurt\\frankfurt_000001_031416_leftImg8bit.png\n",
      "131 val\\frankfurt\\frankfurt_000001_032018_leftImg8bit.png\n",
      "132 val\\frankfurt\\frankfurt_000001_032556_leftImg8bit.png\n",
      "133 val\\frankfurt\\frankfurt_000001_032711_leftImg8bit.png\n",
      "134 val\\frankfurt\\frankfurt_000001_032942_leftImg8bit.png\n",
      "135 val\\frankfurt\\frankfurt_000001_033655_leftImg8bit.png\n",
      "136 val\\frankfurt\\frankfurt_000001_034047_leftImg8bit.png\n",
      "137 val\\frankfurt\\frankfurt_000001_034816_leftImg8bit.png\n",
      "138 val\\frankfurt\\frankfurt_000001_035144_leftImg8bit.png\n",
      "139 val\\frankfurt\\frankfurt_000001_035864_leftImg8bit.png\n",
      "140 val\\frankfurt\\frankfurt_000001_037705_leftImg8bit.png\n",
      "141 val\\frankfurt\\frankfurt_000001_038245_leftImg8bit.png\n",
      "142 val\\frankfurt\\frankfurt_000001_038418_leftImg8bit.png\n",
      "143 val\\frankfurt\\frankfurt_000001_038645_leftImg8bit.png\n",
      "144 val\\frankfurt\\frankfurt_000001_038844_leftImg8bit.png\n",
      "145 val\\frankfurt\\frankfurt_000001_039895_leftImg8bit.png\n",
      "146 val\\frankfurt\\frankfurt_000001_040575_leftImg8bit.png\n",
      "147 val\\frankfurt\\frankfurt_000001_040732_leftImg8bit.png\n",
      "148 val\\frankfurt\\frankfurt_000001_041074_leftImg8bit.png\n",
      "149 val\\frankfurt\\frankfurt_000001_041354_leftImg8bit.png\n",
      "150 val\\frankfurt\\frankfurt_000001_041517_leftImg8bit.png\n",
      "151 val\\frankfurt\\frankfurt_000001_041664_leftImg8bit.png\n",
      "152 val\\frankfurt\\frankfurt_000001_042098_leftImg8bit.png\n",
      "153 val\\frankfurt\\frankfurt_000001_042384_leftImg8bit.png\n",
      "154 val\\frankfurt\\frankfurt_000001_042733_leftImg8bit.png\n",
      "155 val\\frankfurt\\frankfurt_000001_043395_leftImg8bit.png\n",
      "156 val\\frankfurt\\frankfurt_000001_043564_leftImg8bit.png\n",
      "157 val\\frankfurt\\frankfurt_000001_044227_leftImg8bit.png\n",
      "158 val\\frankfurt\\frankfurt_000001_044413_leftImg8bit.png\n",
      "159 val\\frankfurt\\frankfurt_000001_044525_leftImg8bit.png\n",
      "160 val\\frankfurt\\frankfurt_000001_044658_leftImg8bit.png\n",
      "161 val\\frankfurt\\frankfurt_000001_044787_leftImg8bit.png\n",
      "162 val\\frankfurt\\frankfurt_000001_046126_leftImg8bit.png\n",
      "163 val\\frankfurt\\frankfurt_000001_046272_leftImg8bit.png\n",
      "164 val\\frankfurt\\frankfurt_000001_046504_leftImg8bit.png\n",
      "165 val\\frankfurt\\frankfurt_000001_046779_leftImg8bit.png\n",
      "166 val\\frankfurt\\frankfurt_000001_047178_leftImg8bit.png\n",
      "167 val\\frankfurt\\frankfurt_000001_047552_leftImg8bit.png\n",
      "168 val\\frankfurt\\frankfurt_000001_048196_leftImg8bit.png\n",
      "169 val\\frankfurt\\frankfurt_000001_048355_leftImg8bit.png\n",
      "170 val\\frankfurt\\frankfurt_000001_048654_leftImg8bit.png\n",
      "171 val\\frankfurt\\frankfurt_000001_049078_leftImg8bit.png\n",
      "172 val\\frankfurt\\frankfurt_000001_049209_leftImg8bit.png\n",
      "173 val\\frankfurt\\frankfurt_000001_049298_leftImg8bit.png\n",
      "174 val\\frankfurt\\frankfurt_000001_049698_leftImg8bit.png\n",
      "175 val\\frankfurt\\frankfurt_000001_049770_leftImg8bit.png\n",
      "176 val\\frankfurt\\frankfurt_000001_050149_leftImg8bit.png\n",
      "177 val\\frankfurt\\frankfurt_000001_050686_leftImg8bit.png\n",
      "178 val\\frankfurt\\frankfurt_000001_051516_leftImg8bit.png\n",
      "179 val\\frankfurt\\frankfurt_000001_051737_leftImg8bit.png\n",
      "180 val\\frankfurt\\frankfurt_000001_051807_leftImg8bit.png\n",
      "181 val\\frankfurt\\frankfurt_000001_052120_leftImg8bit.png\n",
      "182 val\\frankfurt\\frankfurt_000001_052594_leftImg8bit.png\n",
      "183 val\\frankfurt\\frankfurt_000001_053102_leftImg8bit.png\n",
      "184 val\\frankfurt\\frankfurt_000001_054077_leftImg8bit.png\n",
      "185 val\\frankfurt\\frankfurt_000001_054219_leftImg8bit.png\n",
      "186 val\\frankfurt\\frankfurt_000001_054415_leftImg8bit.png\n",
      "187 val\\frankfurt\\frankfurt_000001_054640_leftImg8bit.png\n",
      "188 val\\frankfurt\\frankfurt_000001_054884_leftImg8bit.png\n",
      "189 val\\frankfurt\\frankfurt_000001_055062_leftImg8bit.png\n",
      "190 val\\frankfurt\\frankfurt_000001_055172_leftImg8bit.png\n",
      "191 val\\frankfurt\\frankfurt_000001_055306_leftImg8bit.png\n",
      "192 val\\frankfurt\\frankfurt_000001_055387_leftImg8bit.png\n",
      "193 val\\frankfurt\\frankfurt_000001_055538_leftImg8bit.png\n",
      "194 val\\frankfurt\\frankfurt_000001_055603_leftImg8bit.png\n",
      "195 val\\frankfurt\\frankfurt_000001_055709_leftImg8bit.png\n",
      "196 val\\frankfurt\\frankfurt_000001_056580_leftImg8bit.png\n",
      "197 val\\frankfurt\\frankfurt_000001_057181_leftImg8bit.png\n",
      "198 val\\frankfurt\\frankfurt_000001_057478_leftImg8bit.png\n",
      "199 val\\frankfurt\\frankfurt_000001_057954_leftImg8bit.png\n",
      "200 val\\frankfurt\\frankfurt_000001_058057_leftImg8bit.png\n",
      "201 val\\frankfurt\\frankfurt_000001_058176_leftImg8bit.png\n",
      "202 val\\frankfurt\\frankfurt_000001_058504_leftImg8bit.png\n",
      "203 val\\frankfurt\\frankfurt_000001_058914_leftImg8bit.png\n",
      "204 val\\frankfurt\\frankfurt_000001_059119_leftImg8bit.png\n",
      "205 val\\frankfurt\\frankfurt_000001_059642_leftImg8bit.png\n",
      "206 val\\frankfurt\\frankfurt_000001_059789_leftImg8bit.png\n",
      "207 val\\frankfurt\\frankfurt_000001_060135_leftImg8bit.png\n",
      "208 val\\frankfurt\\frankfurt_000001_060422_leftImg8bit.png\n",
      "209 val\\frankfurt\\frankfurt_000001_060545_leftImg8bit.png\n",
      "210 val\\frankfurt\\frankfurt_000001_060906_leftImg8bit.png\n",
      "211 val\\frankfurt\\frankfurt_000001_061682_leftImg8bit.png\n",
      "212 val\\frankfurt\\frankfurt_000001_061763_leftImg8bit.png\n",
      "213 val\\frankfurt\\frankfurt_000001_062016_leftImg8bit.png\n",
      "214 val\\frankfurt\\frankfurt_000001_062250_leftImg8bit.png\n",
      "215 val\\frankfurt\\frankfurt_000001_062396_leftImg8bit.png\n",
      "216 val\\frankfurt\\frankfurt_000001_062509_leftImg8bit.png\n",
      "217 val\\frankfurt\\frankfurt_000001_062653_leftImg8bit.png\n",
      "218 val\\frankfurt\\frankfurt_000001_062793_leftImg8bit.png\n",
      "219 val\\frankfurt\\frankfurt_000001_063045_leftImg8bit.png\n",
      "220 val\\frankfurt\\frankfurt_000001_064130_leftImg8bit.png\n",
      "221 val\\frankfurt\\frankfurt_000001_064305_leftImg8bit.png\n",
      "222 val\\frankfurt\\frankfurt_000001_064651_leftImg8bit.png\n",
      "223 val\\frankfurt\\frankfurt_000001_064798_leftImg8bit.png\n",
      "224 val\\frankfurt\\frankfurt_000001_064925_leftImg8bit.png\n",
      "225 val\\frankfurt\\frankfurt_000001_065160_leftImg8bit.png\n",
      "226 val\\frankfurt\\frankfurt_000001_065617_leftImg8bit.png\n",
      "227 val\\frankfurt\\frankfurt_000001_065850_leftImg8bit.png\n",
      "228 val\\frankfurt\\frankfurt_000001_066092_leftImg8bit.png\n",
      "229 val\\frankfurt\\frankfurt_000001_066438_leftImg8bit.png\n",
      "230 val\\frankfurt\\frankfurt_000001_066574_leftImg8bit.png\n",
      "231 val\\frankfurt\\frankfurt_000001_066832_leftImg8bit.png\n",
      "232 val\\frankfurt\\frankfurt_000001_067092_leftImg8bit.png\n",
      "233 val\\frankfurt\\frankfurt_000001_067178_leftImg8bit.png\n",
      "234 val\\frankfurt\\frankfurt_000001_067295_leftImg8bit.png\n",
      "235 val\\frankfurt\\frankfurt_000001_067474_leftImg8bit.png\n",
      "236 val\\frankfurt\\frankfurt_000001_067735_leftImg8bit.png\n",
      "237 val\\frankfurt\\frankfurt_000001_068063_leftImg8bit.png\n",
      "238 val\\frankfurt\\frankfurt_000001_068208_leftImg8bit.png\n",
      "239 val\\frankfurt\\frankfurt_000001_068682_leftImg8bit.png\n",
      "240 val\\frankfurt\\frankfurt_000001_068772_leftImg8bit.png\n",
      "241 val\\frankfurt\\frankfurt_000001_069633_leftImg8bit.png\n",
      "242 val\\frankfurt\\frankfurt_000001_070099_leftImg8bit.png\n",
      "243 val\\frankfurt\\frankfurt_000001_071288_leftImg8bit.png\n",
      "244 val\\frankfurt\\frankfurt_000001_071781_leftImg8bit.png\n",
      "245 val\\frankfurt\\frankfurt_000001_072155_leftImg8bit.png\n",
      "246 val\\frankfurt\\frankfurt_000001_072295_leftImg8bit.png\n",
      "247 val\\frankfurt\\frankfurt_000001_073088_leftImg8bit.png\n",
      "248 val\\frankfurt\\frankfurt_000001_073243_leftImg8bit.png\n",
      "249 val\\frankfurt\\frankfurt_000001_073464_leftImg8bit.png\n",
      "250 val\\frankfurt\\frankfurt_000001_073911_leftImg8bit.png\n",
      "251 val\\frankfurt\\frankfurt_000001_075296_leftImg8bit.png\n",
      "252 val\\frankfurt\\frankfurt_000001_075984_leftImg8bit.png\n",
      "253 val\\frankfurt\\frankfurt_000001_076502_leftImg8bit.png\n",
      "254 val\\frankfurt\\frankfurt_000001_077092_leftImg8bit.png\n",
      "255 val\\frankfurt\\frankfurt_000001_077233_leftImg8bit.png\n",
      "256 val\\frankfurt\\frankfurt_000001_077434_leftImg8bit.png\n",
      "257 val\\frankfurt\\frankfurt_000001_078803_leftImg8bit.png\n",
      "258 val\\frankfurt\\frankfurt_000001_079206_leftImg8bit.png\n",
      "259 val\\frankfurt\\frankfurt_000001_080091_leftImg8bit.png\n",
      "260 val\\frankfurt\\frankfurt_000001_080391_leftImg8bit.png\n",
      "261 val\\frankfurt\\frankfurt_000001_080830_leftImg8bit.png\n",
      "262 val\\frankfurt\\frankfurt_000001_082087_leftImg8bit.png\n",
      "263 val\\frankfurt\\frankfurt_000001_082466_leftImg8bit.png\n",
      "264 val\\frankfurt\\frankfurt_000001_083029_leftImg8bit.png\n",
      "265 val\\frankfurt\\frankfurt_000001_083199_leftImg8bit.png\n",
      "266 val\\frankfurt\\frankfurt_000001_083852_leftImg8bit.png\n",
      "267 val\\lindau\\lindau_000000_000019_leftImg8bit.png\n",
      "268 val\\lindau\\lindau_000001_000019_leftImg8bit.png\n",
      "269 val\\lindau\\lindau_000002_000019_leftImg8bit.png\n",
      "270 val\\lindau\\lindau_000003_000019_leftImg8bit.png\n",
      "271 val\\lindau\\lindau_000004_000019_leftImg8bit.png\n",
      "272 val\\lindau\\lindau_000005_000019_leftImg8bit.png\n",
      "273 val\\lindau\\lindau_000006_000019_leftImg8bit.png\n",
      "274 val\\lindau\\lindau_000007_000019_leftImg8bit.png\n",
      "275 val\\lindau\\lindau_000008_000019_leftImg8bit.png\n",
      "276 val\\lindau\\lindau_000009_000019_leftImg8bit.png\n",
      "277 val\\lindau\\lindau_000010_000019_leftImg8bit.png\n",
      "278 val\\lindau\\lindau_000011_000019_leftImg8bit.png\n",
      "279 val\\lindau\\lindau_000012_000019_leftImg8bit.png\n",
      "280 val\\lindau\\lindau_000013_000019_leftImg8bit.png\n",
      "281 val\\lindau\\lindau_000014_000019_leftImg8bit.png\n",
      "282 val\\lindau\\lindau_000015_000019_leftImg8bit.png\n",
      "283 val\\lindau\\lindau_000016_000019_leftImg8bit.png\n",
      "284 val\\lindau\\lindau_000017_000019_leftImg8bit.png\n",
      "285 val\\lindau\\lindau_000018_000019_leftImg8bit.png\n",
      "286 val\\lindau\\lindau_000019_000019_leftImg8bit.png\n",
      "287 val\\lindau\\lindau_000020_000019_leftImg8bit.png\n",
      "288 val\\lindau\\lindau_000021_000019_leftImg8bit.png\n",
      "289 val\\lindau\\lindau_000022_000019_leftImg8bit.png\n",
      "290 val\\lindau\\lindau_000023_000019_leftImg8bit.png\n",
      "291 val\\lindau\\lindau_000024_000019_leftImg8bit.png\n",
      "292 val\\lindau\\lindau_000025_000019_leftImg8bit.png\n",
      "293 val\\lindau\\lindau_000026_000019_leftImg8bit.png\n",
      "294 val\\lindau\\lindau_000027_000019_leftImg8bit.png\n",
      "295 val\\lindau\\lindau_000028_000019_leftImg8bit.png\n",
      "296 val\\lindau\\lindau_000029_000019_leftImg8bit.png\n",
      "297 val\\lindau\\lindau_000030_000019_leftImg8bit.png\n",
      "298 val\\lindau\\lindau_000031_000019_leftImg8bit.png\n",
      "299 val\\lindau\\lindau_000032_000019_leftImg8bit.png\n",
      "300 val\\lindau\\lindau_000033_000019_leftImg8bit.png\n",
      "301 val\\lindau\\lindau_000034_000019_leftImg8bit.png\n",
      "302 val\\lindau\\lindau_000035_000019_leftImg8bit.png\n",
      "303 val\\lindau\\lindau_000036_000019_leftImg8bit.png\n",
      "304 val\\lindau\\lindau_000037_000019_leftImg8bit.png\n",
      "305 val\\lindau\\lindau_000038_000019_leftImg8bit.png\n",
      "306 val\\lindau\\lindau_000039_000019_leftImg8bit.png\n",
      "307 val\\lindau\\lindau_000040_000019_leftImg8bit.png\n",
      "308 val\\lindau\\lindau_000041_000019_leftImg8bit.png\n",
      "309 val\\lindau\\lindau_000042_000019_leftImg8bit.png\n",
      "310 val\\lindau\\lindau_000043_000019_leftImg8bit.png\n",
      "311 val\\lindau\\lindau_000044_000019_leftImg8bit.png\n",
      "312 val\\lindau\\lindau_000045_000019_leftImg8bit.png\n",
      "313 val\\lindau\\lindau_000046_000019_leftImg8bit.png\n",
      "314 val\\lindau\\lindau_000047_000019_leftImg8bit.png\n",
      "315 val\\lindau\\lindau_000048_000019_leftImg8bit.png\n",
      "316 val\\lindau\\lindau_000049_000019_leftImg8bit.png\n",
      "317 val\\lindau\\lindau_000050_000019_leftImg8bit.png\n",
      "318 val\\lindau\\lindau_000051_000019_leftImg8bit.png\n",
      "319 val\\lindau\\lindau_000052_000019_leftImg8bit.png\n",
      "320 val\\lindau\\lindau_000053_000019_leftImg8bit.png\n",
      "321 val\\lindau\\lindau_000054_000019_leftImg8bit.png\n",
      "322 val\\lindau\\lindau_000055_000019_leftImg8bit.png\n",
      "323 val\\lindau\\lindau_000056_000019_leftImg8bit.png\n",
      "324 val\\lindau\\lindau_000057_000019_leftImg8bit.png\n",
      "325 val\\lindau\\lindau_000058_000019_leftImg8bit.png\n",
      "326 val\\munster\\munster_000000_000019_leftImg8bit.png\n",
      "327 val\\munster\\munster_000001_000019_leftImg8bit.png\n",
      "328 val\\munster\\munster_000002_000019_leftImg8bit.png\n",
      "329 val\\munster\\munster_000003_000019_leftImg8bit.png\n",
      "330 val\\munster\\munster_000004_000019_leftImg8bit.png\n",
      "331 val\\munster\\munster_000005_000019_leftImg8bit.png\n",
      "332 val\\munster\\munster_000006_000019_leftImg8bit.png\n",
      "333 val\\munster\\munster_000007_000019_leftImg8bit.png\n",
      "334 val\\munster\\munster_000008_000019_leftImg8bit.png\n",
      "335 val\\munster\\munster_000009_000019_leftImg8bit.png\n",
      "336 val\\munster\\munster_000010_000019_leftImg8bit.png\n",
      "337 val\\munster\\munster_000011_000019_leftImg8bit.png\n",
      "338 val\\munster\\munster_000012_000019_leftImg8bit.png\n",
      "339 val\\munster\\munster_000013_000019_leftImg8bit.png\n",
      "340 val\\munster\\munster_000014_000019_leftImg8bit.png\n",
      "341 val\\munster\\munster_000015_000019_leftImg8bit.png\n",
      "342 val\\munster\\munster_000016_000019_leftImg8bit.png\n",
      "343 val\\munster\\munster_000017_000019_leftImg8bit.png\n",
      "344 val\\munster\\munster_000018_000019_leftImg8bit.png\n",
      "345 val\\munster\\munster_000019_000019_leftImg8bit.png\n",
      "346 val\\munster\\munster_000020_000019_leftImg8bit.png\n",
      "347 val\\munster\\munster_000021_000019_leftImg8bit.png\n",
      "348 val\\munster\\munster_000022_000019_leftImg8bit.png\n",
      "349 val\\munster\\munster_000023_000019_leftImg8bit.png\n",
      "350 val\\munster\\munster_000024_000019_leftImg8bit.png\n",
      "351 val\\munster\\munster_000025_000019_leftImg8bit.png\n",
      "352 val\\munster\\munster_000026_000019_leftImg8bit.png\n",
      "353 val\\munster\\munster_000027_000019_leftImg8bit.png\n",
      "354 val\\munster\\munster_000028_000019_leftImg8bit.png\n",
      "355 val\\munster\\munster_000029_000019_leftImg8bit.png\n",
      "356 val\\munster\\munster_000030_000019_leftImg8bit.png\n",
      "357 val\\munster\\munster_000031_000019_leftImg8bit.png\n",
      "358 val\\munster\\munster_000032_000019_leftImg8bit.png\n",
      "359 val\\munster\\munster_000033_000019_leftImg8bit.png\n",
      "360 val\\munster\\munster_000034_000019_leftImg8bit.png\n",
      "361 val\\munster\\munster_000035_000019_leftImg8bit.png\n",
      "362 val\\munster\\munster_000036_000019_leftImg8bit.png\n",
      "363 val\\munster\\munster_000037_000019_leftImg8bit.png\n",
      "364 val\\munster\\munster_000038_000019_leftImg8bit.png\n",
      "365 val\\munster\\munster_000039_000019_leftImg8bit.png\n",
      "366 val\\munster\\munster_000040_000019_leftImg8bit.png\n",
      "367 val\\munster\\munster_000041_000019_leftImg8bit.png\n",
      "368 val\\munster\\munster_000042_000019_leftImg8bit.png\n",
      "369 val\\munster\\munster_000043_000019_leftImg8bit.png\n",
      "370 val\\munster\\munster_000044_000019_leftImg8bit.png\n",
      "371 val\\munster\\munster_000045_000019_leftImg8bit.png\n",
      "372 val\\munster\\munster_000046_000019_leftImg8bit.png\n",
      "373 val\\munster\\munster_000047_000019_leftImg8bit.png\n",
      "374 val\\munster\\munster_000048_000019_leftImg8bit.png\n",
      "375 val\\munster\\munster_000049_000019_leftImg8bit.png\n",
      "376 val\\munster\\munster_000050_000019_leftImg8bit.png\n",
      "377 val\\munster\\munster_000051_000019_leftImg8bit.png\n",
      "378 val\\munster\\munster_000052_000019_leftImg8bit.png\n",
      "379 val\\munster\\munster_000053_000019_leftImg8bit.png\n",
      "380 val\\munster\\munster_000054_000019_leftImg8bit.png\n",
      "381 val\\munster\\munster_000055_000019_leftImg8bit.png\n",
      "382 val\\munster\\munster_000056_000019_leftImg8bit.png\n",
      "383 val\\munster\\munster_000057_000019_leftImg8bit.png\n",
      "384 val\\munster\\munster_000058_000019_leftImg8bit.png\n",
      "385 val\\munster\\munster_000059_000019_leftImg8bit.png\n",
      "386 val\\munster\\munster_000060_000019_leftImg8bit.png\n",
      "387 val\\munster\\munster_000061_000019_leftImg8bit.png\n",
      "388 val\\munster\\munster_000062_000019_leftImg8bit.png\n",
      "389 val\\munster\\munster_000063_000019_leftImg8bit.png\n",
      "390 val\\munster\\munster_000064_000019_leftImg8bit.png\n",
      "391 val\\munster\\munster_000065_000019_leftImg8bit.png\n",
      "392 val\\munster\\munster_000066_000019_leftImg8bit.png\n",
      "393 val\\munster\\munster_000067_000019_leftImg8bit.png\n",
      "394 val\\munster\\munster_000068_000019_leftImg8bit.png\n",
      "395 val\\munster\\munster_000069_000019_leftImg8bit.png\n",
      "396 val\\munster\\munster_000070_000019_leftImg8bit.png\n",
      "397 val\\munster\\munster_000071_000019_leftImg8bit.png\n",
      "398 val\\munster\\munster_000072_000019_leftImg8bit.png\n",
      "399 val\\munster\\munster_000073_000019_leftImg8bit.png\n",
      "400 val\\munster\\munster_000074_000019_leftImg8bit.png\n",
      "401 val\\munster\\munster_000075_000019_leftImg8bit.png\n",
      "402 val\\munster\\munster_000076_000019_leftImg8bit.png\n",
      "403 val\\munster\\munster_000077_000019_leftImg8bit.png\n",
      "404 val\\munster\\munster_000078_000019_leftImg8bit.png\n",
      "405 val\\munster\\munster_000079_000019_leftImg8bit.png\n",
      "406 val\\munster\\munster_000080_000019_leftImg8bit.png\n",
      "407 val\\munster\\munster_000081_000019_leftImg8bit.png\n",
      "408 val\\munster\\munster_000082_000019_leftImg8bit.png\n",
      "409 val\\munster\\munster_000083_000019_leftImg8bit.png\n",
      "410 val\\munster\\munster_000084_000019_leftImg8bit.png\n",
      "411 val\\munster\\munster_000085_000019_leftImg8bit.png\n",
      "412 val\\munster\\munster_000086_000019_leftImg8bit.png\n",
      "413 val\\munster\\munster_000087_000019_leftImg8bit.png\n",
      "414 val\\munster\\munster_000088_000019_leftImg8bit.png\n",
      "415 val\\munster\\munster_000089_000019_leftImg8bit.png\n",
      "416 val\\munster\\munster_000090_000019_leftImg8bit.png\n",
      "417 val\\munster\\munster_000091_000019_leftImg8bit.png\n",
      "418 val\\munster\\munster_000092_000019_leftImg8bit.png\n",
      "419 val\\munster\\munster_000093_000019_leftImg8bit.png\n",
      "420 val\\munster\\munster_000094_000019_leftImg8bit.png\n",
      "421 val\\munster\\munster_000095_000019_leftImg8bit.png\n",
      "422 val\\munster\\munster_000096_000019_leftImg8bit.png\n",
      "423 val\\munster\\munster_000097_000019_leftImg8bit.png\n",
      "424 val\\munster\\munster_000098_000019_leftImg8bit.png\n",
      "425 val\\munster\\munster_000099_000019_leftImg8bit.png\n",
      "426 val\\munster\\munster_000100_000019_leftImg8bit.png\n",
      "427 val\\munster\\munster_000101_000019_leftImg8bit.png\n",
      "428 val\\munster\\munster_000102_000019_leftImg8bit.png\n",
      "429 val\\munster\\munster_000103_000019_leftImg8bit.png\n",
      "430 val\\munster\\munster_000104_000019_leftImg8bit.png\n",
      "431 val\\munster\\munster_000105_000019_leftImg8bit.png\n",
      "432 val\\munster\\munster_000106_000019_leftImg8bit.png\n",
      "433 val\\munster\\munster_000107_000019_leftImg8bit.png\n",
      "434 val\\munster\\munster_000108_000019_leftImg8bit.png\n",
      "435 val\\munster\\munster_000109_000019_leftImg8bit.png\n",
      "436 val\\munster\\munster_000110_000019_leftImg8bit.png\n",
      "437 val\\munster\\munster_000111_000019_leftImg8bit.png\n",
      "438 val\\munster\\munster_000112_000019_leftImg8bit.png\n",
      "439 val\\munster\\munster_000113_000019_leftImg8bit.png\n",
      "440 val\\munster\\munster_000114_000019_leftImg8bit.png\n",
      "441 val\\munster\\munster_000115_000019_leftImg8bit.png\n",
      "442 val\\munster\\munster_000116_000019_leftImg8bit.png\n",
      "443 val\\munster\\munster_000117_000019_leftImg8bit.png\n",
      "444 val\\munster\\munster_000118_000019_leftImg8bit.png\n",
      "445 val\\munster\\munster_000119_000019_leftImg8bit.png\n",
      "446 val\\munster\\munster_000120_000019_leftImg8bit.png\n",
      "447 val\\munster\\munster_000121_000019_leftImg8bit.png\n",
      "448 val\\munster\\munster_000122_000019_leftImg8bit.png\n",
      "449 val\\munster\\munster_000123_000019_leftImg8bit.png\n",
      "450 val\\munster\\munster_000124_000019_leftImg8bit.png\n",
      "451 val\\munster\\munster_000125_000019_leftImg8bit.png\n",
      "452 val\\munster\\munster_000126_000019_leftImg8bit.png\n",
      "453 val\\munster\\munster_000127_000019_leftImg8bit.png\n",
      "454 val\\munster\\munster_000128_000019_leftImg8bit.png\n",
      "455 val\\munster\\munster_000129_000019_leftImg8bit.png\n",
      "456 val\\munster\\munster_000130_000019_leftImg8bit.png\n",
      "457 val\\munster\\munster_000131_000019_leftImg8bit.png\n",
      "458 val\\munster\\munster_000132_000019_leftImg8bit.png\n",
      "459 val\\munster\\munster_000133_000019_leftImg8bit.png\n",
      "460 val\\munster\\munster_000134_000019_leftImg8bit.png\n",
      "461 val\\munster\\munster_000135_000019_leftImg8bit.png\n",
      "462 val\\munster\\munster_000136_000019_leftImg8bit.png\n",
      "463 val\\munster\\munster_000137_000019_leftImg8bit.png\n",
      "464 val\\munster\\munster_000138_000019_leftImg8bit.png\n",
      "465 val\\munster\\munster_000139_000019_leftImg8bit.png\n",
      "466 val\\munster\\munster_000140_000019_leftImg8bit.png\n",
      "467 val\\munster\\munster_000141_000019_leftImg8bit.png\n",
      "468 val\\munster\\munster_000142_000019_leftImg8bit.png\n",
      "469 val\\munster\\munster_000143_000019_leftImg8bit.png\n",
      "470 val\\munster\\munster_000144_000019_leftImg8bit.png\n",
      "471 val\\munster\\munster_000145_000019_leftImg8bit.png\n",
      "472 val\\munster\\munster_000146_000019_leftImg8bit.png\n",
      "473 val\\munster\\munster_000147_000019_leftImg8bit.png\n",
      "474 val\\munster\\munster_000148_000019_leftImg8bit.png\n",
      "475 val\\munster\\munster_000149_000019_leftImg8bit.png\n",
      "476 val\\munster\\munster_000150_000019_leftImg8bit.png\n",
      "477 val\\munster\\munster_000151_000019_leftImg8bit.png\n",
      "478 val\\munster\\munster_000152_000019_leftImg8bit.png\n",
      "479 val\\munster\\munster_000153_000019_leftImg8bit.png\n",
      "480 val\\munster\\munster_000154_000019_leftImg8bit.png\n",
      "481 val\\munster\\munster_000155_000019_leftImg8bit.png\n",
      "482 val\\munster\\munster_000156_000019_leftImg8bit.png\n",
      "483 val\\munster\\munster_000157_000019_leftImg8bit.png\n",
      "484 val\\munster\\munster_000158_000019_leftImg8bit.png\n",
      "485 val\\munster\\munster_000159_000019_leftImg8bit.png\n",
      "486 val\\munster\\munster_000160_000019_leftImg8bit.png\n",
      "487 val\\munster\\munster_000161_000019_leftImg8bit.png\n",
      "488 val\\munster\\munster_000162_000019_leftImg8bit.png\n",
      "489 val\\munster\\munster_000163_000019_leftImg8bit.png\n",
      "490 val\\munster\\munster_000164_000019_leftImg8bit.png\n",
      "491 val\\munster\\munster_000165_000019_leftImg8bit.png\n",
      "492 val\\munster\\munster_000166_000019_leftImg8bit.png\n",
      "493 val\\munster\\munster_000167_000019_leftImg8bit.png\n",
      "494 val\\munster\\munster_000168_000019_leftImg8bit.png\n",
      "495 val\\munster\\munster_000169_000019_leftImg8bit.png\n",
      "496 val\\munster\\munster_000170_000019_leftImg8bit.png\n",
      "497 val\\munster\\munster_000171_000019_leftImg8bit.png\n",
      "498 val\\munster\\munster_000172_000019_leftImg8bit.png\n",
      "499 val\\munster\\munster_000173_000019_leftImg8bit.png\n",
      "---------------------------------------\n",
      "Took  34.896628618240356 seconds\n",
      "=======================================\n",
      "Per-Class IoU:\n",
      "\u001B[0m97.01\u001B[0m Road\n",
      "\u001B[0m78.20\u001B[0m sidewalk\n",
      "\u001B[0m89.42\u001B[0m building\n",
      "\u001B[0m47.60\u001B[0m wall\n",
      "\u001B[0m48.95\u001B[0m fence\n",
      "\u001B[0m55.60\u001B[0m pole\n",
      "\u001B[0m53.60\u001B[0m traffic light\n",
      "\u001B[0m64.80\u001B[0m traffic sign\n",
      "\u001B[0m90.43\u001B[0m vegetation\n",
      "\u001B[0m60.44\u001B[0m terrain\n",
      "\u001B[0m92.64\u001B[0m sky\n",
      "\u001B[0m70.42\u001B[0m person\n",
      "\u001B[0m50.46\u001B[0m rider\n",
      "\u001B[0m90.80\u001B[0m car\n",
      "\u001B[0m56.30\u001B[0m truck\n",
      "\u001B[0m66.41\u001B[0m bus\n",
      "\u001B[0m57.65\u001B[0m train\n",
      "\u001B[0m44.24\u001B[0m motorcycle\n",
      "\u001B[0m64.30\u001B[0m bicycle\n",
      "=======================================\n",
      "MEAN IoU:  \u001B[0m67.33\u001B[0m %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vcata\\Desktop\\Polito\\AML\\AnomalySegmentation\\eval\\eval_iou.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T09:54:08.365265Z",
     "start_time": "2024-12-30T09:54:03.844030Z"
    }
   },
   "cell_type": "code",
   "source": "!python  \"C:/Users/vcata\\Desktop\\Polito\\AML\\AnomalySegmentation\\eval/temp_scaling.py\" --datadir \"C:/Users/vcata\\Downloads\\leftImg8bit_trainvaltest\" --loadDir \"C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentation\" --loadWeights \"/save/erfnet_training1/erfnet_pretrained.pth\"",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentationerfnet.py\n",
      "Loading weights: C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentation/save/erfnet_training1/erfnet_pretrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vcata\\Desktop\\Polito\\AML\\AnomalySegmentation\\eval\\temp_scaling.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vcata\\Desktop\\Polito\\AML\\AnomalySegmentation\\eval\\temp_scaling.py\", line 93, in <module>\n",
      "    main(parser.parse_args())\n",
      "  File \"C:\\Users\\vcata\\Desktop\\Polito\\AML\\AnomalySegmentation\\eval\\temp_scaling.py\", line 51, in main\n",
      "    model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\vcata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 1319, in load\n",
      "    with _open_file_like(f, \"rb\") as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\vcata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 659, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\vcata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 640, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentation/save/erfnet_training1/erfnet_pretrained.pth'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "### eval anomaly",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": " !python \"evalAnomaly.py\" --input \"C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\" --loadDir \"C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentation\" --loadWeights \"/trained_models/model_best_log_norm.pth\" --metric maxlogit",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-23T10:56:10.387130Z",
     "iopub.execute_input": "2024-12-23T10:56:10.387451Z",
     "iopub.status.idle": "2024-12-23T10:56:23.578362Z",
     "shell.execute_reply.started": "2024-12-23T10:56:10.387426Z",
     "shell.execute_reply": "2024-12-23T10:56:23.577231Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-02T16:23:08.809217Z",
     "start_time": "2025-01-02T16:22:37.577955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentationerfnet.py\n",
      "Loading weights: C:/Users/vcata/Desktop/Polito/AML/AnomalySegmentation/trained_models/model_best_log_norm.pth\n",
      "Model and weights LOADED successfully\n",
      "ptha C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\0.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\1.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\10.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\11.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\12.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\13.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\14.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\15.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\16.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\17.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\18.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\19.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\2.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\20.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\21.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\22.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\23.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\24.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\25.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\26.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\27.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\28.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\29.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\3.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\4.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\5.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\6.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\7.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\8.jpg\n",
      "Processing image: C:\\Users\\vcata\\Desktop\\Validation_Dataset\\fs_static\\images\\9.jpg\n",
      "AUPRC score: 2.0370685433875693\n",
      "FPR@TPR95: 96.29454280430512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vcata\\Desktop\\Polito\\AML\\AnomalySegmentation\\eval\\evalAnomaly.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Robba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "directory = \"C:/Users/vcata/Downloads/dataset_ObstacleTrack/images/\"\n",
    "print(f\"Contenuto della directory: {os.listdir(directory)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "base_path = Path(\"C:/Users/vcata/Downloads/dataset_ObstacleTrack/images\")\n",
    "files = list(base_path.glob(\"*.webp\"))\n",
    "print(f\"File trovati con pathlib: {[str(file) for file in files]}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
